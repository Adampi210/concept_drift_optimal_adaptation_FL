Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 32.75410842895508
<__main__.Policy object at 0x14c18a409a00>
32.75410842895508
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 1 took 3.8761651515960693s, results:
{'t': 0, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 2 took 3.4756393432617188s, results:
{'t': 1, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 3 took 3.2585883140563965s, results:
{'t': 2, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 4 took 3.3630707263946533s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 5 took 3.822791576385498s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 6 took 3.835766315460205s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 7 took 3.950183868408203s, results:
{'t': 6, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 8 took 3.986368417739868s, results:
{'t': 7, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 9 took 3.942589521408081s, results:
{'t': 8, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 10 took 3.7734150886535645s, results:
{'t': 9, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 11 took 3.559615135192871s, results:
{'t': 10, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 12 took 3.4334356784820557s, results:
{'t': 11, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 13 took 3.3688769340515137s, results:
{'t': 12, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 14 took 3.1770431995391846s, results:
{'t': 13, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 15 took 3.2835328578948975s, results:
{'t': 14, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 16 took 3.330348253250122s, results:
{'t': 15, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 17 took 3.292736768722534s, results:
{'t': 16, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 18 took 2.9997036457061768s, results:
{'t': 17, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 19 took 2.925348997116089s, results:
{'t': 18, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 20 took 2.9217817783355713s, results:
{'t': 19, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.23773193359375; Loss Difference: 0.0, Decision: 0
Round 21 took 3.166797161102295s, results:
{'t': 20, 'current_accuracy': 0.1171875, 'current_loss': 34.99184036254883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 22 took 2.795992851257324s, results:
{'t': 21, 'current_accuracy': 0.15625, 'current_loss': 32.48988723754883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 23 took 2.862847089767456s, results:
{'t': 22, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 24 took 2.777691602706909s, results:
{'t': 23, 'current_accuracy': 0.1484375, 'current_loss': 32.09970283508301, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 25 took 2.916128635406494s, results:
{'t': 24, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 26 took 2.9611623287200928s, results:
{'t': 25, 'current_accuracy': 0.1484375, 'current_loss': 32.099703788757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 27 took 2.8242733478546143s, results:
{'t': 26, 'current_accuracy': 0.1484375, 'current_loss': 32.09970188140869, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 28 took 2.723154306411743s, results:
{'t': 27, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 29 took 2.8550820350646973s, results:
{'t': 28, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 30 took 2.752410888671875s, results:
{'t': 29, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 31 took 2.814148426055908s, results:
{'t': 30, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 32 took 2.8970916271209717s, results:
{'t': 31, 'current_accuracy': 0.1484375, 'current_loss': 32.099700927734375, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 33 took 2.8162686824798584s, results:
{'t': 32, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 34 took 2.951809883117676s, results:
{'t': 33, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 35 took 3.2315866947174072s, results:
{'t': 34, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 36 took 3.204742431640625s, results:
{'t': 35, 'current_accuracy': 0.1484375, 'current_loss': 32.09970188140869, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 37 took 3.2258970737457275s, results:
{'t': 36, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 38 took 3.0759692192077637s, results:
{'t': 37, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 39 took 3.234266519546509s, results:
{'t': 38, 'current_accuracy': 0.1484375, 'current_loss': 32.09970283508301, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 40 took 3.4907758235931396s, results:
{'t': 39, 'current_accuracy': 0.1484375, 'current_loss': 32.099703788757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 41 took 3.8415489196777344s, results:
{'t': 40, 'current_accuracy': 0.1484375, 'current_loss': 32.09969997406006, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 42 took 3.6332902908325195s, results:
{'t': 41, 'current_accuracy': 0.1484375, 'current_loss': 32.099703788757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 7.62939453125e-06; Loss Difference: 0.0, Decision: 0
Round 43 took 3.733484983444214s, results:
{'t': 42, 'current_accuracy': 0.1484375, 'current_loss': 32.09970760345459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 44 took 3.5579640865325928s, results:
{'t': 43, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 45 took 3.2348134517669678s, results:
{'t': 44, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 7.62939453125e-06; Loss Difference: 0.0, Decision: 0
Round 46 took 3.44734787940979s, results:
{'t': 45, 'current_accuracy': 0.1484375, 'current_loss': 32.09970760345459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 7.62939453125e-06; Loss Difference: 0.0, Decision: 0
Round 47 took 3.2252533435821533s, results:
{'t': 46, 'current_accuracy': 0.1484375, 'current_loss': 32.09970760345459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 7.62939453125e-06; Loss Difference: 0.0, Decision: 0
Round 48 took 3.044807195663452s, results:
{'t': 47, 'current_accuracy': 0.1484375, 'current_loss': 32.09970760345459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 49 took 3.190793514251709s, results:
{'t': 48, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 50 took 3.2977118492126465s, results:
{'t': 49, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 51 took 3.0562446117401123s, results:
{'t': 50, 'current_accuracy': 0.1484375, 'current_loss': 32.09970283508301, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 52 took 2.9374020099639893s, results:
{'t': 51, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 53 took 2.8252346515655518s, results:
{'t': 52, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 54 took 3.1708178520202637s, results:
{'t': 53, 'current_accuracy': 0.1484375, 'current_loss': 32.099703788757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 8.58306884765625e-06; Loss Difference: 0.0, Decision: 0
Round 55 took 3.0714988708496094s, results:
{'t': 54, 'current_accuracy': 0.1484375, 'current_loss': 32.099708557128906, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 8.58306884765625e-06; Loss Difference: 0.0, Decision: 0
Round 56 took 3.056680917739868s, results:
{'t': 55, 'current_accuracy': 0.1484375, 'current_loss': 32.099708557128906, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 57 took 2.9919216632843018s, results:
{'t': 56, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 58 took 2.926325798034668s, results:
{'t': 57, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 59 took 3.202204704284668s, results:
{'t': 58, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 60 took 3.1430344581604004s, results:
{'t': 59, 'current_accuracy': 0.1484375, 'current_loss': 32.09970664978027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 61 took 2.9648919105529785s, results:
{'t': 60, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 62 took 2.7112228870391846s, results:
{'t': 61, 'current_accuracy': 0.1484375, 'current_loss': 32.09970569610596, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 63 took 2.6636154651641846s, results:
{'t': 62, 'current_accuracy': 0.1484375, 'current_loss': 32.09970474243164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['sketch']}
Loss historical diff: 1.0310134887695312; Loss Difference: 0.0, Decision: 0
Round 64 took 2.971935272216797s, results:
{'t': 63, 'current_accuracy': 0.12109375, 'current_loss': 33.13071346282959, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['photo']}
Loss historical diff: 0.5511388778686523; Loss Difference: 0.0, Decision: 0
Round 65 took 2.7914717197418213s, results:
{'t': 64, 'current_accuracy': 0.14453125, 'current_loss': 32.65083885192871, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['photo']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 66 took 2.7008602619171143s, results:
{'t': 65, 'current_accuracy': 0.16015625, 'current_loss': 32.00124454498291, 'train_loss': None, 'decision': 0, 'drift_rate': 0.35, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 67 took 2.878359317779541s, results:
{'t': 66, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 68 took 3.078423500061035s, results:
{'t': 67, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 69 took 2.859987497329712s, results:
{'t': 68, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 70 took 2.7232601642608643s, results:
{'t': 69, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 71 took 2.7432501316070557s, results:
{'t': 70, 'current_accuracy': 0.16015625, 'current_loss': 32.001243591308594, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 72 took 3.0640857219696045s, results:
{'t': 71, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 73 took 2.809993267059326s, results:
{'t': 72, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 74 took 2.722395658493042s, results:
{'t': 73, 'current_accuracy': 0.16015625, 'current_loss': 32.00124454498291, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 75 took 2.949801445007324s, results:
{'t': 74, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 76 took 2.929156541824341s, results:
{'t': 75, 'current_accuracy': 0.16015625, 'current_loss': 32.00124549865723, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 77 took 3.102921724319458s, results:
{'t': 76, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 78 took 3.118809223175049s, results:
{'t': 77, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 79 took 3.321101188659668s, results:
{'t': 78, 'current_accuracy': 0.16015625, 'current_loss': 32.00124549865723, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 80 took 3.4140894412994385s, results:
{'t': 79, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 81 took 3.033452033996582s, results:
{'t': 80, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 82 took 3.0299265384674072s, results:
{'t': 81, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 83 took 2.9967756271362305s, results:
{'t': 82, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 84 took 3.251171112060547s, results:
{'t': 83, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.62939453125e-06; Loss Difference: 0.0, Decision: 0
Round 85 took 3.3905816078186035s, results:
{'t': 84, 'current_accuracy': 0.16015625, 'current_loss': 32.001251220703125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 86 took 2.891719102859497s, results:
{'t': 85, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 87 took 3.0176267623901367s, results:
{'t': 86, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 88 took 2.9512946605682373s, results:
{'t': 87, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 89 took 2.9024460315704346s, results:
{'t': 88, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 90 took 2.8689255714416504s, results:
{'t': 89, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 91 took 2.8488609790802s, results:
{'t': 90, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 92 took 2.9747884273529053s, results:
{'t': 91, 'current_accuracy': 0.16015625, 'current_loss': 32.00125026702881, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 93 took 3.2767796516418457s, results:
{'t': 92, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 94 took 3.335940361022949s, results:
{'t': 93, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 95 took 3.1922545433044434s, results:
{'t': 94, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 96 took 3.1144919395446777s, results:
{'t': 95, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 97 took 3.094701051712036s, results:
{'t': 96, 'current_accuracy': 0.16015625, 'current_loss': 32.00124454498291, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.814697265625e-06; Loss Difference: 0.0, Decision: 0
Round 98 took 2.768707513809204s, results:
{'t': 97, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 99 took 2.7478322982788086s, results:
{'t': 98, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 100 took 2.727130651473999s, results:
{'t': 99, 'current_accuracy': 0.16015625, 'current_loss': 32.00124549865723, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 101 took 2.822657823562622s, results:
{'t': 100, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 102 took 2.7428085803985596s, results:
{'t': 101, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 103 took 3.0396487712860107s, results:
{'t': 102, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 104 took 2.8207595348358154s, results:
{'t': 103, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.9073486328125e-06; Loss Difference: 0.0, Decision: 0
Round 105 took 2.8429617881774902s, results:
{'t': 104, 'current_accuracy': 0.16015625, 'current_loss': 32.00124549865723, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 106 took 2.814594268798828s, results:
{'t': 105, 'current_accuracy': 0.16015625, 'current_loss': 32.00125026702881, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 107 took 2.941347360610962s, results:
{'t': 106, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 108 took 2.747684955596924s, results:
{'t': 107, 'current_accuracy': 0.16015625, 'current_loss': 32.00124454498291, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 109 took 2.6967504024505615s, results:
{'t': 108, 'current_accuracy': 0.16015625, 'current_loss': 32.00125026702881, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.86102294921875e-06; Loss Difference: 0.0, Decision: 0
Round 110 took 2.7157576084136963s, results:
{'t': 109, 'current_accuracy': 0.16015625, 'current_loss': 32.00124645233154, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 111 took 2.8323581218719482s, results:
{'t': 110, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 112 took 2.744251251220703s, results:
{'t': 111, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 113 took 2.752227544784546s, results:
{'t': 112, 'current_accuracy': 0.16015625, 'current_loss': 32.00124263763428, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 6.67572021484375e-06; Loss Difference: 0.0, Decision: 0
Round 114 took 2.9329519271850586s, results:
{'t': 113, 'current_accuracy': 0.16015625, 'current_loss': 32.00124931335449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-06; Loss Difference: 0.0, Decision: 0
Round 115 took 2.9658050537109375s, results:
{'t': 114, 'current_accuracy': 0.16015625, 'current_loss': 32.00124740600586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 5.7220458984375e-06; Loss Difference: 0.0, Decision: 0
Round 116 took 2.8123576641082764s, results:
{'t': 115, 'current_accuracy': 0.16015625, 'current_loss': 32.001248359680176, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.337386131286621; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 25.70623016357422
<__main__.Policy object at 0x14841a0ed6d0>
25.70623016357422
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 1 took 5.235472679138184s, results:
{'t': 0, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 2 took 5.041139602661133s, results:
{'t': 1, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 3 took 4.592111349105835s, results:
{'t': 2, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 4 took 4.379544258117676s, results:
{'t': 3, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 5 took 4.753913640975952s, results:
{'t': 4, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 6 took 4.640076160430908s, results:
{'t': 5, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 7 took 4.573519229888916s, results:
{'t': 6, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 8 took 4.8169896602630615s, results:
{'t': 7, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 9 took 4.952454090118408s, results:
{'t': 8, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 10 took 4.4655983448028564s, results:
{'t': 9, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 11 took 4.1963136196136475s, results:
{'t': 10, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 12 took 4.565812587738037s, results:
{'t': 11, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 13 took 4.66507887840271s, results:
{'t': 12, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 14 took 4.065081357955933s, results:
{'t': 13, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 15 took 4.140915632247925s, results:
{'t': 14, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723759651184082; Loss Difference: 0.0, Decision: 0
Round 16 took 4.566950082778931s, results:
{'t': 15, 'current_accuracy': 0.15625, 'current_loss': 28.4299898147583, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 17 took 4.474035024642944s, results:
{'t': 16, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 18 took 4.418917417526245s, results:
{'t': 17, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 19 took 5.237098932266235s, results:
{'t': 18, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 20 took 4.675806999206543s, results:
{'t': 19, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 21 took 4.97339940071106s, results:
{'t': 20, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 22 took 4.742318630218506s, results:
{'t': 21, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 23 took 5.151885509490967s, results:
{'t': 22, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 24 took 5.507682800292969s, results:
{'t': 23, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 25 took 4.958636999130249s, results:
{'t': 24, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 26 took 5.7924065589904785s, results:
{'t': 25, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 27 took 5.428227424621582s, results:
{'t': 26, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 28 took 5.516150951385498s, results:
{'t': 27, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237586975097656; Loss Difference: 0.0, Decision: 0
Round 29 took 5.696268320083618s, results:
{'t': 28, 'current_accuracy': 0.15625, 'current_loss': 28.429988861083984, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 30 took 4.9370787143707275s, results:
{'t': 29, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 31 took 5.482142925262451s, results:
{'t': 30, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 32 took 5.862627029418945s, results:
{'t': 31, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 33 took 5.7379255294799805s, results:
{'t': 32, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 34 took 5.153663396835327s, results:
{'t': 33, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 35 took 5.253880262374878s, results:
{'t': 34, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 36 took 4.824268579483032s, results:
{'t': 35, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 37 took 4.943385601043701s, results:
{'t': 36, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 38 took 5.132271766662598s, results:
{'t': 37, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 39 took 4.799999237060547s, results:
{'t': 38, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 40 took 5.531803131103516s, results:
{'t': 39, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 41 took 4.9191083908081055s, results:
{'t': 40, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 42 took 5.839008569717407s, results:
{'t': 41, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 43 took 6.313678503036499s, results:
{'t': 42, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 44 took 5.959997177124023s, results:
{'t': 43, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 45 took 5.41433048248291s, results:
{'t': 44, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 46 took 4.995905160903931s, results:
{'t': 45, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 47 took 4.844152212142944s, results:
{'t': 46, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 48 took 5.389026403427124s, results:
{'t': 47, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 49 took 4.821895599365234s, results:
{'t': 48, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 50 took 5.042713403701782s, results:
{'t': 49, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3648109436035156; Loss Difference: 0.0, Decision: 0
Round 51 took 4.789736986160278s, results:
{'t': 50, 'current_accuracy': 0.1484375, 'current_loss': 29.071041107177734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.032, 'target_domains': ['photo']}
Loss historical diff: 3.6576013565063477; Loss Difference: 0.0, Decision: 0
Round 52 took 5.1442344188690186s, results:
{'t': 51, 'current_accuracy': 0.140625, 'current_loss': 29.363831520080566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.032, 'target_domains': ['photo']}
Loss historical diff: 3.2085142135620117; Loss Difference: 0.0, Decision: 0
Round 53 took 4.875501871109009s, results:
{'t': 52, 'current_accuracy': 0.1484375, 'current_loss': 28.91474437713623, 'train_loss': None, 'decision': 0, 'drift_rate': 0.032, 'target_domains': ['photo']}
Loss historical diff: 3.662796974182129; Loss Difference: 0.0, Decision: 0
Round 54 took 5.194276332855225s, results:
{'t': 53, 'current_accuracy': 0.14453125, 'current_loss': 29.369027137756348, 'train_loss': None, 'decision': 0, 'drift_rate': 0.032, 'target_domains': ['photo']}
Loss historical diff: 3.774519920349121; Loss Difference: 0.0, Decision: 0
Round 55 took 4.631990909576416s, results:
{'t': 54, 'current_accuracy': 0.140625, 'current_loss': 29.48075008392334, 'train_loss': None, 'decision': 0, 'drift_rate': 0.032, 'target_domains': ['photo']}
Loss historical diff: 4.42984676361084; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 138.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 140.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 74.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 2.67 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 73, in forward
    out = self.bn2(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 

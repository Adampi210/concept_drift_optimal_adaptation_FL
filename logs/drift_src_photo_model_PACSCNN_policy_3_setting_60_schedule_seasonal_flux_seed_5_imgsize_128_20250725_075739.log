Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 34.80974578857422
<__main__.Policy object at 0x14e5d7c756d0>
34.80974578857422
Loss historical diff: 2.1208839416503906; Loss Difference: 0.0, Decision: 0
Round 1 took 4.869622230529785s, results:
{'t': 0, 'current_accuracy': 0.20703125, 'current_loss': 36.93062973022461, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208877563476562; Loss Difference: 0.0, Decision: 0
Round 2 took 3.5771560668945312s, results:
{'t': 1, 'current_accuracy': 0.20703125, 'current_loss': 36.930633544921875, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.120889663696289; Loss Difference: 0.0, Decision: 0
Round 3 took 4.196657180786133s, results:
{'t': 2, 'current_accuracy': 0.20703125, 'current_loss': 36.93063545227051, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208839416503906; Loss Difference: 0.0, Decision: 0
Round 4 took 4.267322063446045s, results:
{'t': 3, 'current_accuracy': 0.20703125, 'current_loss': 36.93062973022461, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.120889663696289; Loss Difference: 0.0, Decision: 0
Round 5 took 4.120425224304199s, results:
{'t': 4, 'current_accuracy': 0.20703125, 'current_loss': 36.93063545227051, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208839416503906; Loss Difference: 0.0, Decision: 0
Round 6 took 4.763127565383911s, results:
{'t': 5, 'current_accuracy': 0.20703125, 'current_loss': 36.93062973022461, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208877563476562; Loss Difference: 0.0, Decision: 0
Round 7 took 4.305835485458374s, results:
{'t': 6, 'current_accuracy': 0.20703125, 'current_loss': 36.930633544921875, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208839416503906; Loss Difference: 0.0, Decision: 0
Round 8 took 4.465718030929565s, results:
{'t': 7, 'current_accuracy': 0.20703125, 'current_loss': 36.93062973022461, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208858489990234; Loss Difference: 0.0, Decision: 0
Round 9 took 4.350024700164795s, results:
{'t': 8, 'current_accuracy': 0.20703125, 'current_loss': 36.93063163757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.1208877563476562; Loss Difference: 0.0, Decision: 0
Round 10 took 4.4195027351379395s, results:
{'t': 9, 'current_accuracy': 0.20703125, 'current_loss': 36.930633544921875, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 2.120882034301758; Loss Difference: 0.0, Decision: 0
Round 11 took 4.0843024253845215s, results:
{'t': 10, 'current_accuracy': 0.20703125, 'current_loss': 36.93062782287598, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001, 'target_domains': ['photo']}
Loss historical diff: 2.1208858489990234; Loss Difference: 0.0, Decision: 0
Round 12 took 4.19495964050293s, results:
{'t': 11, 'current_accuracy': 0.20703125, 'current_loss': 36.93063163757324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001670010459667194, 'target_domains': ['sketch']}
Loss historical diff: 2.120882034301758; Loss Difference: 0.0, Decision: 0
Round 13 took 4.162803888320923s, results:
{'t': 12, 'current_accuracy': 0.20703125, 'current_loss': 36.93062782287598, 'train_loss': None, 'decision': 0, 'drift_rate': 0.002338845493317048, 'target_domains': ['sketch']}
Loss historical diff: 2.1208877563476562; Loss Difference: 0.0, Decision: 0
Round 14 took 4.744617700576782s, results:
{'t': 13, 'current_accuracy': 0.20703125, 'current_loss': 36.930633544921875, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003005331737028868, 'target_domains': ['sketch']}
Loss historical diff: 2.1208839416503906; Loss Difference: 0.0, Decision: 0
Round 15 took 4.29229736328125s, results:
{'t': 14, 'current_accuracy': 0.20703125, 'current_loss': 36.93062973022461, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003668299947457636, 'target_domains': ['sketch']}
Loss historical diff: 2.3409862518310547; Loss Difference: 0.0, Decision: 0
Round 16 took 4.518143653869629s, results:
{'t': 15, 'current_accuracy': 0.203125, 'current_loss': 37.15073204040527, 'train_loss': None, 'decision': 0, 'drift_rate': 0.00432658705308415, 'target_domains': ['sketch']}
Loss historical diff: 2.5809669494628906; Loss Difference: 0.0, Decision: 0
Round 17 took 4.207892179489136s, results:
{'t': 16, 'current_accuracy': 0.203125, 'current_loss': 37.39071273803711, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0049790381946376765, 'target_domains': ['sketch']}
Loss historical diff: 2.3294525146484375; Loss Difference: 0.0, Decision: 0
Round 18 took 4.693811655044556s, results:
{'t': 17, 'current_accuracy': 0.20703125, 'current_loss': 37.139198303222656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.005624508751111546, 'target_domains': ['sketch']}
Loss historical diff: 2.4972095489501953; Loss Difference: 0.0, Decision: 0
Round 19 took 4.24940037727356s, results:
{'t': 18, 'current_accuracy': 0.20703125, 'current_loss': 37.306955337524414, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006261866347817332, 'target_domains': ['sketch']}
Loss historical diff: 2.599611282348633; Loss Difference: 0.0, Decision: 0
Round 20 took 4.351211071014404s, results:
{'t': 19, 'current_accuracy': 0.20703125, 'current_loss': 37.40935707092285, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006889992842954847, 'target_domains': ['sketch']}
Loss historical diff: 2.4373645782470703; Loss Difference: 0.0, Decision: 0
Round 21 took 5.055022478103638s, results:
{'t': 20, 'current_accuracy': 0.20703125, 'current_loss': 37.24711036682129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.007507786289212803, 'target_domains': ['sketch']}
Loss historical diff: 2.2800426483154297; Loss Difference: 0.0, Decision: 0
Round 22 took 5.07584547996521s, results:
{'t': 21, 'current_accuracy': 0.20703125, 'current_loss': 37.08978843688965, 'train_loss': None, 'decision': 0, 'drift_rate': 0.00811416286695884, 'target_domains': ['sketch']}
Loss historical diff: 2.584890365600586; Loss Difference: 0.0, Decision: 0
Round 23 took 4.518393278121948s, results:
{'t': 22, 'current_accuracy': 0.20703125, 'current_loss': 37.394636154174805, 'train_loss': None, 'decision': 0, 'drift_rate': 0.008708058785627446, 'target_domains': ['sketch']}
Loss historical diff: 2.519195556640625; Loss Difference: 0.0, Decision: 0
Round 24 took 4.276943922042847s, results:
{'t': 23, 'current_accuracy': 0.20703125, 'current_loss': 37.328941345214844, 'train_loss': None, 'decision': 0, 'drift_rate': 0.009288432149970084, 'target_domains': ['sketch']}
Loss historical diff: 2.4929580688476562; Loss Difference: 0.0, Decision: 0
Round 25 took 4.246387720108032s, results:
{'t': 24, 'current_accuracy': 0.20703125, 'current_loss': 37.302703857421875, 'train_loss': None, 'decision': 0, 'drift_rate': 0.009854264787893505, 'target_domains': ['sketch']}
Loss historical diff: 2.7669010162353516; Loss Difference: 0.0, Decision: 0
Round 26 took 4.251847743988037s, results:
{'t': 25, 'current_accuracy': 0.203125, 'current_loss': 37.57664680480957, 'train_loss': None, 'decision': 0, 'drift_rate': 0.01040456403667957, 'target_domains': ['sketch']}
Loss historical diff: 2.804941177368164; Loss Difference: 0.0, Decision: 0
Round 27 took 3.8886868953704834s, results:
{'t': 26, 'current_accuracy': 0.19921875, 'current_loss': 37.61468696594238, 'train_loss': None, 'decision': 0, 'drift_rate': 0.010938364484452966, 'target_domains': ['sketch']}
Loss historical diff: 3.2810802459716797; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

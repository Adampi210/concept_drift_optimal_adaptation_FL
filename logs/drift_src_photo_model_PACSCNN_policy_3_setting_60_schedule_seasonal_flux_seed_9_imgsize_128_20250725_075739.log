Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 32.75410842895508
<__main__.Policy object at 0x1503fea2de50>
32.75410842895508
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 1 took 3.4212539196014404s, results:
{'t': 0, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 2 took 3.372018575668335s, results:
{'t': 1, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 3 took 4.00948166847229s, results:
{'t': 2, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 4 took 3.498518943786621s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 5 took 3.693739175796509s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 6 took 4.238303899765015s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 7 took 3.8824470043182373s, results:
{'t': 6, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 8 took 4.489143133163452s, results:
{'t': 7, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 9 took 3.814790725708008s, results:
{'t': 8, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 10 took 3.9446218013763428s, results:
{'t': 9, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 11 took 3.3398678302764893s, results:
{'t': 10, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 12 took 3.9006717205047607s, results:
{'t': 11, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001670010459667194, 'target_domains': ['sketch']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 13 took 3.74401593208313s, results:
{'t': 12, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.002338845493317048, 'target_domains': ['sketch']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 14 took 3.935091733932495s, results:
{'t': 13, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003005331737028868, 'target_domains': ['sketch']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 15 took 3.7663986682891846s, results:
{'t': 14, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003668299947457636, 'target_domains': ['sketch']}
Loss historical diff: 3.135051727294922; Loss Difference: 0.0, Decision: 0
Round 16 took 4.2984373569488525s, results:
{'t': 15, 'current_accuracy': 0.09375, 'current_loss': 35.88916015625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.00432658705308415, 'target_domains': ['sketch']}
Loss historical diff: 3.2324657440185547; Loss Difference: 0.0, Decision: 0
Round 17 took 3.7569363117218018s, results:
{'t': 16, 'current_accuracy': 0.09375, 'current_loss': 35.98657417297363, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0049790381946376765, 'target_domains': ['sketch']}
Loss historical diff: 3.273366928100586; Loss Difference: 0.0, Decision: 1
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 77, in update_steps
    loss.backward()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED

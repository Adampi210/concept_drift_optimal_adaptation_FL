Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 7.408046245574951
<__main__.Policy object at 0x14a891019610>
7.408046245574951
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 1 took 3.9141108989715576s, results:
{'t': 0, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778729438781738; Loss Difference: 0.0, Decision: 0
Round 2 took 3.7504360675811768s, results:
{'t': 1, 'current_accuracy': 0.1171875, 'current_loss': 8.285919189453125, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778729438781738; Loss Difference: 0.0, Decision: 0
Round 3 took 3.686955213546753s, results:
{'t': 2, 'current_accuracy': 0.1171875, 'current_loss': 8.285919189453125, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778722286224365; Loss Difference: 0.0, Decision: 0
Round 4 took 3.6745800971984863s, results:
{'t': 3, 'current_accuracy': 0.1171875, 'current_loss': 8.285918474197388, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 5 took 3.580021858215332s, results:
{'t': 4, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778727054595947; Loss Difference: 0.0, Decision: 0
Round 6 took 3.907796859741211s, results:
{'t': 5, 'current_accuracy': 0.1171875, 'current_loss': 8.285918951034546, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.877873420715332; Loss Difference: 0.0, Decision: 0
Round 7 took 3.7330474853515625s, results:
{'t': 6, 'current_accuracy': 0.1171875, 'current_loss': 8.285919666290283, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778722286224365; Loss Difference: 0.0, Decision: 0
Round 8 took 3.843975782394409s, results:
{'t': 7, 'current_accuracy': 0.1171875, 'current_loss': 8.285918474197388, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 9 took 4.004221677780151s, results:
{'t': 8, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 10 took 3.6764135360717773s, results:
{'t': 9, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0, 'target_domains': ['cartoon']}
Loss historical diff: 0.8778717517852783; Loss Difference: 0.0, Decision: 0
Round 11 took 3.7035913467407227s, results:
{'t': 10, 'current_accuracy': 0.1171875, 'current_loss': 8.28591799736023, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001, 'target_domains': ['photo']}
Loss historical diff: 0.8778715133666992; Loss Difference: 0.0, Decision: 0
Round 12 took 3.6918656826019287s, results:
{'t': 11, 'current_accuracy': 0.1171875, 'current_loss': 8.28591775894165, 'train_loss': None, 'decision': 0, 'drift_rate': 0.001670010459667194, 'target_domains': ['sketch']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 13 took 3.8163959980010986s, results:
{'t': 12, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0.002338845493317048, 'target_domains': ['sketch']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 14 took 3.746650457382202s, results:
{'t': 13, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003005331737028868, 'target_domains': ['sketch']}
Loss historical diff: 0.8778724670410156; Loss Difference: 0.0, Decision: 0
Round 15 took 3.782428026199341s, results:
{'t': 14, 'current_accuracy': 0.1171875, 'current_loss': 8.285918712615967, 'train_loss': None, 'decision': 0, 'drift_rate': 0.003668299947457636, 'target_domains': ['sketch']}
Loss historical diff: 0.8893303871154785; Loss Difference: 0.0, Decision: 0
Round 16 took 4.269461631774902s, results:
{'t': 15, 'current_accuracy': 0.1171875, 'current_loss': 8.29737663269043, 'train_loss': None, 'decision': 0, 'drift_rate': 0.00432658705308415, 'target_domains': ['sketch']}
Loss historical diff: 0.8959417343139648; Loss Difference: 0.0, Decision: 0
Round 17 took 3.8973429203033447s, results:
{'t': 16, 'current_accuracy': 0.11328125, 'current_loss': 8.303987979888916, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0049790381946376765, 'target_domains': ['sketch']}
Loss historical diff: 0.8685660362243652; Loss Difference: 0.0, Decision: 0
Round 18 took 3.7131435871124268s, results:
{'t': 17, 'current_accuracy': 0.11328125, 'current_loss': 8.276612281799316, 'train_loss': None, 'decision': 0, 'drift_rate': 0.005624508751111546, 'target_domains': ['sketch']}
Loss historical diff: 0.7903347015380859; Loss Difference: 0.0, Decision: 0
Round 19 took 3.7736217975616455s, results:
{'t': 18, 'current_accuracy': 0.1171875, 'current_loss': 8.198380947113037, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006261866347817332, 'target_domains': ['sketch']}
Loss historical diff: 0.7491540908813477; Loss Difference: 0.0, Decision: 0
Round 20 took 3.4775640964508057s, results:
{'t': 19, 'current_accuracy': 0.1171875, 'current_loss': 8.157200336456299, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006889992842954847, 'target_domains': ['sketch']}
Loss historical diff: 0.7558856010437012; Loss Difference: 0.0, Decision: 0
Round 21 took 3.9177963733673096s, results:
{'t': 20, 'current_accuracy': 0.11328125, 'current_loss': 8.163931846618652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.007507786289212803, 'target_domains': ['sketch']}
Loss historical diff: 0.8280942440032959; Loss Difference: 0.0, Decision: 0
Round 22 took 4.0197694301605225s, results:
{'t': 21, 'current_accuracy': 0.109375, 'current_loss': 8.236140489578247, 'train_loss': None, 'decision': 0, 'drift_rate': 0.00811416286695884, 'target_domains': ['sketch']}
Loss historical diff: 0.8366508483886719; Loss Difference: 0.0, Decision: 1
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 77, in update_steps
    loss.backward()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
Exception in thread Thread-49 (_pin_memory_loop):
Traceback (most recent call last):
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 54, in _pin_memory_loop
    do_one_step()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 31, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
         ^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 525, in Client
    answer_challenge(c, authkey)
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 953, in answer_challenge
    message = connection.recv_bytes(256)         # reject large message
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 395, in _recv
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

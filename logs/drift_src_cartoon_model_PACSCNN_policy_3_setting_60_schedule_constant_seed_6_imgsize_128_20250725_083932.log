Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 7.408046245574951
<__main__.Policy object at 0x15508f532540>
7.408046245574951
Loss historical diff: 1.0140752792358398; Loss Difference: 0.0, Decision: 0
Round 1 took 6.839526414871216s, results:
{'t': 0, 'current_accuracy': 0.1171875, 'current_loss': 8.422121524810791, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.1281657218933105; Loss Difference: 0.0, Decision: 0
Round 2 took 6.162273645401001s, results:
{'t': 1, 'current_accuracy': 0.109375, 'current_loss': 8.536211967468262, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.0910425186157227; Loss Difference: 0.0, Decision: 0
Round 3 took 5.730423212051392s, results:
{'t': 2, 'current_accuracy': 0.10546875, 'current_loss': 8.499088764190674, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.1952309608459473; Loss Difference: 0.0, Decision: 0
Round 4 took 6.18336820602417s, results:
{'t': 3, 'current_accuracy': 0.10546875, 'current_loss': 8.603277206420898, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.2653322219848633; Loss Difference: 0.0, Decision: 0
Round 5 took 5.850842475891113s, results:
{'t': 4, 'current_accuracy': 0.1015625, 'current_loss': 8.673378467559814, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3061671257019043; Loss Difference: 0.0, Decision: 0
Round 6 took 6.276073455810547s, results:
{'t': 5, 'current_accuracy': 0.10546875, 'current_loss': 8.714213371276855, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3290185928344727; Loss Difference: 0.0, Decision: 0
Round 7 took 6.0351879596710205s, results:
{'t': 6, 'current_accuracy': 0.1015625, 'current_loss': 8.737064838409424, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4689831733703613; Loss Difference: 0.0, Decision: 0
Round 8 took 6.594163417816162s, results:
{'t': 7, 'current_accuracy': 0.10546875, 'current_loss': 8.877029418945312, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4433808326721191; Loss Difference: 0.0, Decision: 0
Round 9 took 6.2208075523376465s, results:
{'t': 8, 'current_accuracy': 0.11328125, 'current_loss': 8.85142707824707, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.522017478942871; Loss Difference: 0.0, Decision: 0
Round 10 took 6.90929102897644s, results:
{'t': 9, 'current_accuracy': 0.11328125, 'current_loss': 8.930063724517822, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.563232421875; Loss Difference: 0.0, Decision: 0
Round 11 took 6.580792188644409s, results:
{'t': 10, 'current_accuracy': 0.1171875, 'current_loss': 8.971278667449951, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.483750820159912; Loss Difference: 0.0, Decision: 0
Round 12 took 6.972149133682251s, results:
{'t': 11, 'current_accuracy': 0.1171875, 'current_loss': 8.891797065734863, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.475365161895752; Loss Difference: 0.0, Decision: 0
Round 13 took 6.521583318710327s, results:
{'t': 12, 'current_accuracy': 0.12109375, 'current_loss': 8.883411407470703, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4217090606689453; Loss Difference: 0.0, Decision: 0
Round 14 took 5.981810092926025s, results:
{'t': 13, 'current_accuracy': 0.125, 'current_loss': 8.829755306243896, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3826899528503418; Loss Difference: 0.0, Decision: 0
Round 15 took 5.676419019699097s, results:
{'t': 14, 'current_accuracy': 0.12890625, 'current_loss': 8.790736198425293, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3759140968322754; Loss Difference: 0.0, Decision: 0
Round 16 took 6.203239679336548s, results:
{'t': 15, 'current_accuracy': 0.12890625, 'current_loss': 8.783960342407227, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3592658042907715; Loss Difference: 0.0, Decision: 0
Round 17 took 5.661734342575073s, results:
{'t': 16, 'current_accuracy': 0.1328125, 'current_loss': 8.767312049865723, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3062381744384766; Loss Difference: 0.0, Decision: 0
Round 18 took 6.210492849349976s, results:
{'t': 17, 'current_accuracy': 0.13671875, 'current_loss': 8.714284420013428, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.2975692749023438; Loss Difference: 0.0, Decision: 0
Round 19 took 5.895329475402832s, results:
{'t': 18, 'current_accuracy': 0.13671875, 'current_loss': 8.705615520477295, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.1788582801818848; Loss Difference: 0.0, Decision: 0
Round 20 took 5.7253804206848145s, results:
{'t': 19, 'current_accuracy': 0.1484375, 'current_loss': 8.586904525756836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3614349365234375; Loss Difference: 0.0, Decision: 0
Round 21 took 6.224821329116821s, results:
{'t': 20, 'current_accuracy': 0.13671875, 'current_loss': 8.769481182098389, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.3713350296020508; Loss Difference: 0.0, Decision: 0
Round 22 took 6.425252199172974s, results:
{'t': 21, 'current_accuracy': 0.140625, 'current_loss': 8.779381275177002, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4691472053527832; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

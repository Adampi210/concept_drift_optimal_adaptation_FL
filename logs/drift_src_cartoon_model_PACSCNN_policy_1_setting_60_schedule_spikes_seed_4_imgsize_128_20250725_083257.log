Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 8.656878471374512
<__main__.Policy object at 0x14badf70d070>
8.656878471374512
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 1 took 4.406096696853638s, results:
{'t': 0, 'current_accuracy': 0.17578125, 'current_loss': 8.427419900894165, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 2 took 4.629079818725586s, results:
{'t': 1, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 3 took 4.610000848770142s, results:
{'t': 2, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.430511474609375e-06; Loss Difference: 0.0, Decision: 0
Round 4 took 4.995725393295288s, results:
{'t': 3, 'current_accuracy': 0.17578125, 'current_loss': 8.42742109298706, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 4.76837158203125e-07; Loss Difference: 0.0, Decision: 0
Round 5 took 4.345031261444092s, results:
{'t': 4, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 4.76837158203125e-07; Loss Difference: 0.0, Decision: 0
Round 6 took 4.913020610809326s, results:
{'t': 5, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.430511474609375e-06; Loss Difference: 0.0, Decision: 0
Round 7 took 4.909504652023315s, results:
{'t': 6, 'current_accuracy': 0.17578125, 'current_loss': 8.42742109298706, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 8 took 5.02341890335083s, results:
{'t': 7, 'current_accuracy': 0.17578125, 'current_loss': 8.427419424057007, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 9 took 5.4950151443481445s, results:
{'t': 8, 'current_accuracy': 0.17578125, 'current_loss': 8.427420616149902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 10 took 6.327385187149048s, results:
{'t': 9, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.6689300537109375e-06; Loss Difference: 0.0, Decision: 0
Round 11 took 5.983363151550293s, results:
{'t': 10, 'current_accuracy': 0.17578125, 'current_loss': 8.42742109298706, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 12 took 6.317115306854248s, results:
{'t': 11, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 13 took 6.899309873580933s, results:
{'t': 12, 'current_accuracy': 0.17578125, 'current_loss': 8.427419424057007, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 14 took 6.1549482345581055s, results:
{'t': 13, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 15 took 6.289998292922974s, results:
{'t': 14, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 16 took 6.1785924434661865s, results:
{'t': 15, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 4.76837158203125e-07; Loss Difference: 0.0, Decision: 0
Round 17 took 6.481591463088989s, results:
{'t': 16, 'current_accuracy': 0.17578125, 'current_loss': 8.427419900894165, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 18 took 6.7902421951293945s, results:
{'t': 17, 'current_accuracy': 0.17578125, 'current_loss': 8.427420616149902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 19 took 6.733356714248657s, results:
{'t': 18, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 20 took 5.736602306365967s, results:
{'t': 19, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 21 took 6.225255966186523s, results:
{'t': 20, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 22 took 5.893265247344971s, results:
{'t': 21, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 23 took 7.269764423370361s, results:
{'t': 22, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 24 took 7.67805027961731s, results:
{'t': 23, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 25 took 6.304743766784668s, results:
{'t': 24, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 26 took 6.890997648239136s, results:
{'t': 25, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 27 took 6.101974248886108s, results:
{'t': 26, 'current_accuracy': 0.17578125, 'current_loss': 8.427420616149902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 28 took 6.0875184535980225s, results:
{'t': 27, 'current_accuracy': 0.17578125, 'current_loss': 8.427420616149902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 29 took 6.629518985748291s, results:
{'t': 28, 'current_accuracy': 0.17578125, 'current_loss': 8.427420616149902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 30 took 5.673118829727173s, results:
{'t': 29, 'current_accuracy': 0.17578125, 'current_loss': 8.427420377731323, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 31 took 6.344839572906494s, results:
{'t': 30, 'current_accuracy': 0.17578125, 'current_loss': 8.427420139312744, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 32 took 5.65201210975647s, results:
{'t': 31, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 33 took 6.2554612159729s, results:
{'t': 32, 'current_accuracy': 0.17578125, 'current_loss': 8.427419424057007, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 34 took 5.955615043640137s, results:
{'t': 33, 'current_accuracy': 0.17578125, 'current_loss': 8.427419662475586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['cartoon']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 35 took 5.423785209655762s, results:
{'t': 34, 'current_accuracy': 0.265625, 'current_loss': 6.94957160949707, 'train_loss': None, 'decision': 0, 'drift_rate': 0.4045581125860249, 'target_domains': ['photo']}
Loss historical diff: 0.06597590446472168; Loss Difference: 0.0, Decision: 0
Round 36 took 5.907212734222412s, results:
{'t': 35, 'current_accuracy': 0.26171875, 'current_loss': 7.015547513961792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.3032028065285197, 'target_domains': ['photo']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 37 took 5.363675117492676s, results:
{'t': 36, 'current_accuracy': 0.29296875, 'current_loss': 6.308640241622925, 'train_loss': None, 'decision': 0, 'drift_rate': 0.42045159259674963, 'target_domains': ['photo']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 38 took 5.331646919250488s, results:
{'t': 37, 'current_accuracy': 0.29296875, 'current_loss': 6.308640480041504, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 39 took 6.226623058319092s, results:
{'t': 38, 'current_accuracy': 0.29296875, 'current_loss': 6.308641195297241, 'train_loss': None, 'decision': 0, 'drift_rate': 0.4433100937973453, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 40 took 5.009242296218872s, results:
{'t': 39, 'current_accuracy': 0.29296875, 'current_loss': 6.308641195297241, 'train_loss': None, 'decision': 0, 'drift_rate': 0.48904494913594454, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 41 took 5.210072994232178s, results:
{'t': 40, 'current_accuracy': 0.29296875, 'current_loss': 6.308641195297241, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-07; Loss Difference: 0.0, Decision: 0
Round 42 took 5.62263035774231s, results:
{'t': 41, 'current_accuracy': 0.29296875, 'current_loss': 6.308640718460083, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 0
Round 43 took 4.935680150985718s, results:
{'t': 42, 'current_accuracy': 0.29296875, 'current_loss': 6.308640480041504, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 1.1920928955078125e-06; Loss Difference: 0.0, Decision: 0
Round 44 took 5.551531553268433s, results:
{'t': 43, 'current_accuracy': 0.29296875, 'current_loss': 6.30864143371582, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 9.5367431640625e-07; Loss Difference: 0.0, Decision: 0
Round 45 took 5.757427453994751s, results:
{'t': 44, 'current_accuracy': 0.29296875, 'current_loss': 6.308641195297241, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 46 took 6.099149703979492s, results:
{'t': 45, 'current_accuracy': 0.29296875, 'current_loss': 6.308640956878662, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.152557373046875e-07; Loss Difference: 0.0, Decision: 0
Round 47 took 5.926795959472656s, results:
{'t': 46, 'current_accuracy': 0.29296875, 'current_loss': 6.308640956878662, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 4.76837158203125e-07; Loss Difference: 0.0, Decision: 0
Round 48 took 5.992089033126831s, results:
{'t': 47, 'current_accuracy': 0.29296875, 'current_loss': 6.308640718460083, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 2.384185791015625e-07; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

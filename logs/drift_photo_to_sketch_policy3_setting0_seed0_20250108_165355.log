/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
seed: 0
policy_id: 3
setting_id: 0
pi_bar: 0.1
drift_rate: 0.01
V: 2
0.04950650425797159 0.2
Round 0: Accuracy = 0.8240, Decision = 0
0.044447961517355666 0.2
Round 1: Accuracy = 0.8116, Decision = 0
0.061196781356226304 0.2
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 317, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 300, in main
    results = retrain_with_policy_under_drift(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 203, in retrain_with_policy_under_drift
    current_loss = client.get_train_metric(metric_fn=criterion, verbose=False)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 106, in get_train_metric
    return self.model.evaluate(self.train_loader, metric_fn, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 63, in evaluate
    for batch in data_loader:
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/dataset.py", line 419, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/data_operations/data_handler.py", line 259, in __getitem__
    image = self.transform(image)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
           ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torchvision/transforms/functional.py", line 168, in to_tensor
    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/PIL/Image.py", line 696, in __array_interface__
    new["data"] = self.tobytes()
                  ^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/PIL/Image.py", line 761, in tobytes
    e = _getencoder(self.mode, encoder_name, args)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/PIL/Image.py", line 429, in _getencoder
    encoder = getattr(core, encoder_name + "_encoder")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 27.21426010131836
<__main__.Policy object at 0x14d1abded6d0>
27.21426010131836
Loss historical diff: 3.3061752319335938; Loss Difference: 0.0, Decision: 0
Round 1 took 3.2768945693969727s, results:
{'t': 0, 'current_accuracy': 0.09765625, 'current_loss': 30.520435333251953, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.358896255493164; Loss Difference: 0.0, Decision: 0
Round 2 took 3.500000476837158s, results:
{'t': 1, 'current_accuracy': 0.09375, 'current_loss': 30.573156356811523, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.128411293029785; Loss Difference: 0.0, Decision: 0
Round 3 took 3.604928731918335s, results:
{'t': 2, 'current_accuracy': 0.08984375, 'current_loss': 30.342671394348145, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.0604896545410156; Loss Difference: 0.0, Decision: 0
Round 4 took 3.68509840965271s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 30.274749755859375, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.9080190658569336; Loss Difference: 0.0, Decision: 0
Round 5 took 3.8550853729248047s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 30.122279167175293, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.453023910522461; Loss Difference: 0.0, Decision: 0
Round 6 took 3.577340602874756s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 29.66728401184082, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.143374443054199; Loss Difference: 0.0, Decision: 0
Round 7 took 3.6813840866088867s, results:
{'t': 6, 'current_accuracy': 0.09375, 'current_loss': 29.35763454437256, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.9675817489624023; Loss Difference: 0.0, Decision: 0
Round 8 took 3.730135202407837s, results:
{'t': 7, 'current_accuracy': 0.09375, 'current_loss': 29.18184185028076, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.9217920303344727; Loss Difference: 0.0, Decision: 0
Round 9 took 3.5334463119506836s, results:
{'t': 8, 'current_accuracy': 0.08984375, 'current_loss': 29.136052131652832, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.9981498718261719; Loss Difference: 0.0, Decision: 0
Round 10 took 3.55606746673584s, results:
{'t': 9, 'current_accuracy': 0.08984375, 'current_loss': 29.21240997314453, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4980087280273438; Loss Difference: 0.0, Decision: 0
Round 11 took 3.5757899284362793s, results:
{'t': 10, 'current_accuracy': 0.08984375, 'current_loss': 28.712268829345703, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.2433347702026367; Loss Difference: 0.0, Decision: 0
Round 12 took 3.5114104747772217s, results:
{'t': 11, 'current_accuracy': 0.09375, 'current_loss': 28.457594871520996, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.0225858688354492; Loss Difference: 0.0, Decision: 0
Round 13 took 3.602349281311035s, results:
{'t': 12, 'current_accuracy': 0.09375, 'current_loss': 28.23684597015381, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.6580123901367188; Loss Difference: 0.0, Decision: 0
Round 14 took 3.8738651275634766s, results:
{'t': 13, 'current_accuracy': 0.09765625, 'current_loss': 27.872272491455078, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.4137306213378906; Loss Difference: 0.0, Decision: 0
Round 15 took 3.631397247314453s, results:
{'t': 14, 'current_accuracy': 0.09375, 'current_loss': 27.62799072265625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.14742374420166016; Loss Difference: 0.0, Decision: 0
Round 16 took 3.5307204723358154s, results:
{'t': 15, 'current_accuracy': 0.09375, 'current_loss': 27.36168384552002, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.04121112823486328; Loss Difference: 0.0, Decision: 0
Round 17 took 3.2964744567871094s, results:
{'t': 16, 'current_accuracy': 0.09375, 'current_loss': 27.255471229553223, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 18 took 3.5904061794281006s, results:
{'t': 17, 'current_accuracy': 0.09765625, 'current_loss': 26.82419204711914, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.17016315460205078; Loss Difference: 0.0, Decision: 0
Round 19 took 3.4796435832977295s, results:
{'t': 18, 'current_accuracy': 0.09375, 'current_loss': 26.99435520172119, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.1645498275756836; Loss Difference: 0.0, Decision: 0
Round 20 took 3.6906816959381104s, results:
{'t': 19, 'current_accuracy': 0.09375, 'current_loss': 26.988741874694824, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 21 took 3.3475749492645264s, results:
{'t': 20, 'current_accuracy': 0.09765625, 'current_loss': 26.444762229919434, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 22 took 3.7801756858825684s, results:
{'t': 21, 'current_accuracy': 0.09765625, 'current_loss': 25.97195053100586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 23 took 3.549666166305542s, results:
{'t': 22, 'current_accuracy': 0.109375, 'current_loss': 25.81540012359619, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.4038810729980469; Loss Difference: 0.0, Decision: 0
Round 24 took 3.5313243865966797s, results:
{'t': 23, 'current_accuracy': 0.109375, 'current_loss': 26.21928119659424, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.23547935485839844; Loss Difference: 0.0, Decision: 0
Round 25 took 3.821312665939331s, results:
{'t': 24, 'current_accuracy': 0.109375, 'current_loss': 26.05087947845459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 26 took 3.619558334350586s, results:
{'t': 25, 'current_accuracy': 0.1171875, 'current_loss': 25.612515449523926, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 27 took 4.004179239273071s, results:
{'t': 26, 'current_accuracy': 0.1171875, 'current_loss': 25.297832489013672, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.3075237274169922; Loss Difference: 0.0, Decision: 0
Round 28 took 4.061968803405762s, results:
{'t': 27, 'current_accuracy': 0.11328125, 'current_loss': 25.605356216430664, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 29 took 3.8078484535217285s, results:
{'t': 28, 'current_accuracy': 0.11328125, 'current_loss': 25.23759937286377, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 30 took 3.518535614013672s, results:
{'t': 29, 'current_accuracy': 0.1171875, 'current_loss': 25.079669952392578, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.03936481475830078; Loss Difference: 0.0, Decision: 0
Round 31 took 3.650569200515747s, results:
{'t': 30, 'current_accuracy': 0.11328125, 'current_loss': 25.11903476715088, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 32 took 3.540133237838745s, results:
{'t': 31, 'current_accuracy': 0.125, 'current_loss': 24.75031280517578, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 33 took 3.596233367919922s, results:
{'t': 32, 'current_accuracy': 0.12890625, 'current_loss': 24.435179710388184, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 34 took 3.2376279830932617s, results:
{'t': 33, 'current_accuracy': 0.1328125, 'current_loss': 24.205921173095703, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 35 took 3.4838273525238037s, results:
{'t': 34, 'current_accuracy': 0.13671875, 'current_loss': 23.80515480041504, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 36 took 3.4529385566711426s, results:
{'t': 35, 'current_accuracy': 0.13671875, 'current_loss': 23.510350227355957, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.2275381088256836; Loss Difference: 0.0, Decision: 0
Round 37 took 3.815751791000366s, results:
{'t': 36, 'current_accuracy': 0.13671875, 'current_loss': 23.73788833618164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.33152198791503906; Loss Difference: 0.0, Decision: 0
Round 38 took 3.947040319442749s, results:
{'t': 37, 'current_accuracy': 0.140625, 'current_loss': 23.841872215270996, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.3828144073486328; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 2.25 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 

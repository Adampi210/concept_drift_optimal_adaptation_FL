Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 27.21426010131836
<__main__.Policy object at 0x1487068b57f0>
27.21426010131836
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 1 took 4.149518966674805s, results:
{'t': 0, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380526542663574; Loss Difference: 0.0, Decision: 0
Round 2 took 3.6062183380126953s, results:
{'t': 1, 'current_accuracy': 0.09375, 'current_loss': 30.594786643981934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.38053035736084; Loss Difference: 0.0, Decision: 0
Round 3 took 3.6894800662994385s, results:
{'t': 2, 'current_accuracy': 0.09375, 'current_loss': 30.5947904586792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 4 took 3.768707513809204s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 5 took 3.620361089706421s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 6 took 3.5876617431640625s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 7 took 3.6069226264953613s, results:
{'t': 6, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 8 took 3.656959056854248s, results:
{'t': 7, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380526542663574; Loss Difference: 0.0, Decision: 0
Round 9 took 3.3895163536071777s, results:
{'t': 8, 'current_accuracy': 0.09375, 'current_loss': 30.594786643981934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.38053035736084; Loss Difference: 0.0, Decision: 0
Round 10 took 3.617846965789795s, results:
{'t': 9, 'current_accuracy': 0.09375, 'current_loss': 30.5947904586792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805246353149414; Loss Difference: 0.0, Decision: 0
Round 11 took 3.947347640991211s, results:
{'t': 10, 'current_accuracy': 0.09375, 'current_loss': 30.5947847366333, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805313110351562; Loss Difference: 0.0, Decision: 0
Round 12 took 3.5192062854766846s, results:
{'t': 11, 'current_accuracy': 0.09375, 'current_loss': 30.594791412353516, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805274963378906; Loss Difference: 0.0, Decision: 0
Round 13 took 3.991067886352539s, results:
{'t': 12, 'current_accuracy': 0.09375, 'current_loss': 30.59478759765625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805246353149414; Loss Difference: 0.0, Decision: 0
Round 14 took 3.3546512126922607s, results:
{'t': 13, 'current_accuracy': 0.09375, 'current_loss': 30.5947847366333, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380525588989258; Loss Difference: 0.0, Decision: 0
Round 15 took 3.482954740524292s, results:
{'t': 14, 'current_accuracy': 0.09375, 'current_loss': 30.594785690307617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805274963378906; Loss Difference: 0.0, Decision: 0
Round 16 took 3.1400842666625977s, results:
{'t': 15, 'current_accuracy': 0.09375, 'current_loss': 30.59478759765625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805313110351562; Loss Difference: 0.0, Decision: 0
Round 17 took 3.8633415699005127s, results:
{'t': 16, 'current_accuracy': 0.09375, 'current_loss': 30.594791412353516, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805227279663086; Loss Difference: 0.0, Decision: 0
Round 18 took 3.9058680534362793s, results:
{'t': 17, 'current_accuracy': 0.09375, 'current_loss': 30.594782829284668, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 19 took 3.8558034896850586s, results:
{'t': 18, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.38053035736084; Loss Difference: 0.0, Decision: 0
Round 20 took 3.667572498321533s, results:
{'t': 19, 'current_accuracy': 0.09375, 'current_loss': 30.5947904586792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805274963378906; Loss Difference: 0.0, Decision: 0
Round 21 took 3.8781158924102783s, results:
{'t': 20, 'current_accuracy': 0.09375, 'current_loss': 30.59478759765625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380526542663574; Loss Difference: 0.0, Decision: 0
Round 22 took 3.4467697143554688s, results:
{'t': 21, 'current_accuracy': 0.09375, 'current_loss': 30.594786643981934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 23 took 3.467597007751465s, results:
{'t': 22, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380523681640625; Loss Difference: 0.0, Decision: 0
Round 24 took 3.618685483932495s, results:
{'t': 23, 'current_accuracy': 0.09375, 'current_loss': 30.594783782958984, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 25 took 3.513143301010132s, results:
{'t': 24, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380526542663574; Loss Difference: 0.0, Decision: 0
Round 26 took 3.4409985542297363s, results:
{'t': 25, 'current_accuracy': 0.09375, 'current_loss': 30.594786643981934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 27 took 3.7326512336730957s, results:
{'t': 26, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.38053035736084; Loss Difference: 0.0, Decision: 0
Round 28 took 3.8973028659820557s, results:
{'t': 27, 'current_accuracy': 0.09375, 'current_loss': 30.5947904586792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805322647094727; Loss Difference: 0.0, Decision: 0
Round 29 took 3.581632137298584s, results:
{'t': 28, 'current_accuracy': 0.09375, 'current_loss': 30.594792366027832, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 30 took 3.5060465335845947s, results:
{'t': 29, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 31 took 3.665436029434204s, results:
{'t': 30, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805246353149414; Loss Difference: 0.0, Decision: 0
Round 32 took 3.4815659523010254s, results:
{'t': 31, 'current_accuracy': 0.09375, 'current_loss': 30.5947847366333, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.38053035736084; Loss Difference: 0.0, Decision: 0
Round 33 took 3.5722057819366455s, results:
{'t': 32, 'current_accuracy': 0.09375, 'current_loss': 30.5947904586792, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 34 took 3.593392848968506s, results:
{'t': 33, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 35 took 3.7772412300109863s, results:
{'t': 34, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 36 took 3.5564053058624268s, results:
{'t': 35, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805341720581055; Loss Difference: 0.0, Decision: 0
Round 37 took 3.5051939487457275s, results:
{'t': 36, 'current_accuracy': 0.09375, 'current_loss': 30.594794273376465, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805313110351562; Loss Difference: 0.0, Decision: 0
Round 38 took 4.02054762840271s, results:
{'t': 37, 'current_accuracy': 0.09375, 'current_loss': 30.594791412353516, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380528450012207; Loss Difference: 0.0, Decision: 0
Round 39 took 3.9352314472198486s, results:
{'t': 38, 'current_accuracy': 0.09375, 'current_loss': 30.594788551330566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380525588989258; Loss Difference: 0.0, Decision: 0
Round 40 took 3.699617862701416s, results:
{'t': 39, 'current_accuracy': 0.09375, 'current_loss': 30.594785690307617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805246353149414; Loss Difference: 0.0, Decision: 0
Round 41 took 3.434098243713379s, results:
{'t': 40, 'current_accuracy': 0.09375, 'current_loss': 30.5947847366333, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380526542663574; Loss Difference: 0.0, Decision: 0
Round 42 took 3.599580764770508s, results:
{'t': 41, 'current_accuracy': 0.09375, 'current_loss': 30.594786643981934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805294036865234; Loss Difference: 0.0, Decision: 0
Round 43 took 3.395414352416992s, results:
{'t': 42, 'current_accuracy': 0.09375, 'current_loss': 30.594789505004883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.3805274963378906; Loss Difference: 0.0, Decision: 0
Round 44 took 3.9119999408721924s, results:
{'t': 43, 'current_accuracy': 0.09375, 'current_loss': 30.59478759765625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.380523681640625; Loss Difference: 0.0, Decision: 0
Round 45 took 3.7827279567718506s, results:
{'t': 44, 'current_accuracy': 0.09375, 'current_loss': 30.594783782958984, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 3.792776107788086; Loss Difference: 0.0, Decision: 0
Round 46 took 3.668213129043579s, results:
{'t': 45, 'current_accuracy': 0.09765625, 'current_loss': 31.007036209106445, 'train_loss': None, 'decision': 0, 'drift_rate': 0.4, 'target_domains': ['photo']}
Loss historical diff: 5.872631072998047; Loss Difference: 0.0, Decision: 0
Round 47 took 3.3629982471466064s, results:
{'t': 46, 'current_accuracy': 0.125, 'current_loss': 33.086891174316406, 'train_loss': None, 'decision': 0, 'drift_rate': 0.4, 'target_domains': ['photo']}
Loss historical diff: 7.16322135925293; Loss Difference: 0.0, Decision: 0
Round 48 took 3.808166980743408s, results:
{'t': 47, 'current_accuracy': 0.12109375, 'current_loss': 34.37748146057129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.4, 'target_domains': ['photo']}
Loss historical diff: 7.1632232666015625; Loss Difference: 0.0, Decision: 0
Round 49 took 3.4149813652038574s, results:
{'t': 48, 'current_accuracy': 0.12109375, 'current_loss': 34.37748336791992, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.16322135925293; Loss Difference: 0.0, Decision: 0
Round 50 took 3.5964784622192383s, results:
{'t': 49, 'current_accuracy': 0.12109375, 'current_loss': 34.37748146057129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.16322135925293; Loss Difference: 0.0, Decision: 0
Round 51 took 3.1666877269744873s, results:
{'t': 50, 'current_accuracy': 0.12109375, 'current_loss': 34.37748146057129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.163225173950195; Loss Difference: 0.0, Decision: 0
Round 52 took 3.407191753387451s, results:
{'t': 51, 'current_accuracy': 0.12109375, 'current_loss': 34.377485275268555, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.163219451904297; Loss Difference: 0.0, Decision: 0
Round 53 took 4.0618016719818115s, results:
{'t': 52, 'current_accuracy': 0.12109375, 'current_loss': 34.377479553222656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.163225173950195; Loss Difference: 0.0, Decision: 0
Round 54 took 3.7565505504608154s, results:
{'t': 53, 'current_accuracy': 0.12109375, 'current_loss': 34.377485275268555, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.163219451904297; Loss Difference: 0.0, Decision: 0
Round 55 took 3.689448833465576s, results:
{'t': 54, 'current_accuracy': 0.12109375, 'current_loss': 34.377479553222656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.163219451904297; Loss Difference: 0.0, Decision: 0
Round 56 took 3.3797414302825928s, results:
{'t': 55, 'current_accuracy': 0.12109375, 'current_loss': 34.377479553222656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.16322135925293; Loss Difference: 0.0, Decision: 0
Round 57 took 3.704258918762207s, results:
{'t': 56, 'current_accuracy': 0.12109375, 'current_loss': 34.37748146057129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.16322135925293; Loss Difference: 0.0, Decision: 0
Round 58 took 3.837838888168335s, results:
{'t': 57, 'current_accuracy': 0.12109375, 'current_loss': 34.37748146057129, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 7.1632232666015625; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

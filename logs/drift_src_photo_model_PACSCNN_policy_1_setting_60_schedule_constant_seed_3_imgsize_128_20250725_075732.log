Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 43.173484802246094
<__main__.Policy object at 0x152daaefd910>
43.173484802246094
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 1 took 2.8745687007904053s, results:
{'t': 0, 'current_accuracy': 0.125, 'current_loss': 42.82805252075195, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.6253452301025391; Loss Difference: 0.0, Decision: 0
Round 2 took 3.3533430099487305s, results:
{'t': 1, 'current_accuracy': 0.125, 'current_loss': 43.45339775085449, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.0441017150878906; Loss Difference: 0.0, Decision: 0
Round 3 took 3.0565216541290283s, results:
{'t': 2, 'current_accuracy': 0.12109375, 'current_loss': 43.872154235839844, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.2489166259765625; Loss Difference: 0.0, Decision: 0
Round 4 took 3.187655448913574s, results:
{'t': 3, 'current_accuracy': 0.12109375, 'current_loss': 44.076969146728516, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.7614307403564453; Loss Difference: 0.0, Decision: 0
Round 5 took 3.4905238151550293s, results:
{'t': 4, 'current_accuracy': 0.125, 'current_loss': 44.5894832611084, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.9283256530761719; Loss Difference: 0.0, Decision: 0
Round 6 took 3.520456314086914s, results:
{'t': 5, 'current_accuracy': 0.12890625, 'current_loss': 44.756378173828125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.434185028076172; Loss Difference: 0.0, Decision: 0
Round 7 took 2.7515196800231934s, results:
{'t': 6, 'current_accuracy': 0.12890625, 'current_loss': 45.262237548828125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.4068145751953125; Loss Difference: 0.0, Decision: 0
Round 8 took 3.0415360927581787s, results:
{'t': 7, 'current_accuracy': 0.1328125, 'current_loss': 45.234867095947266, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.824483871459961; Loss Difference: 0.0, Decision: 0
Round 9 took 2.7654685974121094s, results:
{'t': 8, 'current_accuracy': 0.1328125, 'current_loss': 45.652536392211914, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.2349491119384766; Loss Difference: 0.0, Decision: 0
Round 10 took 2.793617010116577s, results:
{'t': 9, 'current_accuracy': 0.1328125, 'current_loss': 46.06300163269043, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.577850341796875; Loss Difference: 0.0, Decision: 0
Round 11 took 2.6304450035095215s, results:
{'t': 10, 'current_accuracy': 0.1328125, 'current_loss': 46.40590286254883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.507246017456055; Loss Difference: 0.0, Decision: 0
Round 12 took 2.812138319015503s, results:
{'t': 11, 'current_accuracy': 0.1328125, 'current_loss': 47.33529853820801, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.485134124755859; Loss Difference: 0.0, Decision: 0
Round 13 took 2.777374744415283s, results:
{'t': 12, 'current_accuracy': 0.1328125, 'current_loss': 47.31318664550781, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.920286178588867; Loss Difference: 0.0, Decision: 0
Round 14 took 2.8156728744506836s, results:
{'t': 13, 'current_accuracy': 0.1328125, 'current_loss': 47.74833869934082, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.948905944824219; Loss Difference: 0.0, Decision: 0
Round 15 took 2.6675000190734863s, results:
{'t': 14, 'current_accuracy': 0.13671875, 'current_loss': 47.77695846557617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.3796844482421875; Loss Difference: 0.0, Decision: 0
Round 16 took 2.505080223083496s, results:
{'t': 15, 'current_accuracy': 0.1328125, 'current_loss': 48.20773696899414, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.220211029052734; Loss Difference: 0.0, Decision: 0
Round 17 took 2.899350881576538s, results:
{'t': 16, 'current_accuracy': 0.13671875, 'current_loss': 48.04826354980469, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.971075057983398; Loss Difference: 0.0, Decision: 0
Round 18 took 2.5192346572875977s, results:
{'t': 17, 'current_accuracy': 0.140625, 'current_loss': 47.79912757873535, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.367353439331055; Loss Difference: 0.0, Decision: 0
Round 19 took 2.42937970161438s, results:
{'t': 18, 'current_accuracy': 0.14453125, 'current_loss': 48.19540596008301, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.345085144042969; Loss Difference: 0.0, Decision: 0
Round 20 took 2.7388226985931396s, results:
{'t': 19, 'current_accuracy': 0.140625, 'current_loss': 48.17313766479492, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.871746063232422; Loss Difference: 0.0, Decision: 0
Round 21 took 2.663822650909424s, results:
{'t': 20, 'current_accuracy': 0.13671875, 'current_loss': 48.699798583984375, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 5.91676139831543; Loss Difference: 0.0, Decision: 0
Round 22 took 2.67280650138855s, results:
{'t': 21, 'current_accuracy': 0.140625, 'current_loss': 48.74481391906738, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 6.189035415649414; Loss Difference: 0.0, Decision: 0
Round 23 took 2.744014263153076s, results:
{'t': 22, 'current_accuracy': 0.14453125, 'current_loss': 49.01708793640137, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 6.160980224609375; Loss Difference: 0.0, Decision: 0
Round 24 took 2.8915610313415527s, results:
{'t': 23, 'current_accuracy': 0.14453125, 'current_loss': 48.98903274536133, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 6.818851470947266; Loss Difference: 0.0, Decision: 0
Round 25 took 2.562990665435791s, results:
{'t': 24, 'current_accuracy': 0.14453125, 'current_loss': 49.64690399169922, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 7.263128280639648; Loss Difference: 0.0, Decision: 0
Round 26 took 2.372873306274414s, results:
{'t': 25, 'current_accuracy': 0.15234375, 'current_loss': 50.0911808013916, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.063018798828125; Loss Difference: 0.0, Decision: 0
Round 27 took 2.7991650104522705s, results:
{'t': 26, 'current_accuracy': 0.1484375, 'current_loss': 50.89107131958008, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.070316314697266; Loss Difference: 0.0, Decision: 0
Round 28 took 2.7929975986480713s, results:
{'t': 27, 'current_accuracy': 0.15234375, 'current_loss': 50.89836883544922, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.341398239135742; Loss Difference: 0.0, Decision: 0
Round 29 took 2.452416181564331s, results:
{'t': 28, 'current_accuracy': 0.1484375, 'current_loss': 51.169450759887695, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.430252075195312; Loss Difference: 0.0, Decision: 0
Round 30 took 2.6842103004455566s, results:
{'t': 29, 'current_accuracy': 0.15234375, 'current_loss': 51.258304595947266, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.582128524780273; Loss Difference: 0.0, Decision: 0
Round 31 took 2.6452348232269287s, results:
{'t': 30, 'current_accuracy': 0.1484375, 'current_loss': 51.41018104553223, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 8.97098159790039; Loss Difference: 0.0, Decision: 0
Round 32 took 2.623934268951416s, results:
{'t': 31, 'current_accuracy': 0.1484375, 'current_loss': 51.799034118652344, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 9.620500564575195; Loss Difference: 0.0, Decision: 0
Round 33 took 2.5594499111175537s, results:
{'t': 32, 'current_accuracy': 0.15234375, 'current_loss': 52.44855308532715, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 9.682016372680664; Loss Difference: 0.0, Decision: 0
Round 34 took 2.617415428161621s, results:
{'t': 33, 'current_accuracy': 0.15234375, 'current_loss': 52.51006889343262, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 10.667461395263672; Loss Difference: 0.0, Decision: 0
Round 35 took 2.6211459636688232s, results:
{'t': 34, 'current_accuracy': 0.1484375, 'current_loss': 53.495513916015625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 10.813127517700195; Loss Difference: 0.0, Decision: 0
Round 36 took 2.6257264614105225s, results:
{'t': 35, 'current_accuracy': 0.15234375, 'current_loss': 53.64118003845215, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.05034065246582; Loss Difference: 0.0, Decision: 0
Round 37 took 2.579371690750122s, results:
{'t': 36, 'current_accuracy': 0.15625, 'current_loss': 53.87839317321777, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.267627716064453; Loss Difference: 0.0, Decision: 0
Round 38 took 2.618320941925049s, results:
{'t': 37, 'current_accuracy': 0.16015625, 'current_loss': 54.095680236816406, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.636697769165039; Loss Difference: 0.0, Decision: 0
Round 39 took 2.630061626434326s, results:
{'t': 38, 'current_accuracy': 0.15625, 'current_loss': 54.46475028991699, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.32114028930664; Loss Difference: 0.0, Decision: 0
Round 40 took 2.5624518394470215s, results:
{'t': 39, 'current_accuracy': 0.1640625, 'current_loss': 54.149192810058594, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.539632797241211; Loss Difference: 0.0, Decision: 0
Round 41 took 2.6688930988311768s, results:
{'t': 40, 'current_accuracy': 0.16796875, 'current_loss': 54.367685317993164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 11.819355010986328; Loss Difference: 0.0, Decision: 0
Round 42 took 2.502460241317749s, results:
{'t': 41, 'current_accuracy': 0.16796875, 'current_loss': 54.64740753173828, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 12.04556655883789; Loss Difference: 0.0, Decision: 0
Round 43 took 2.555081367492676s, results:
{'t': 42, 'current_accuracy': 0.16796875, 'current_loss': 54.873619079589844, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 12.785331726074219; Loss Difference: 0.0, Decision: 0
Round 44 took 2.5032029151916504s, results:
{'t': 43, 'current_accuracy': 0.1640625, 'current_loss': 55.61338424682617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 12.803291320800781; Loss Difference: 0.0, Decision: 0
Round 45 took 2.5517466068267822s, results:
{'t': 44, 'current_accuracy': 0.16796875, 'current_loss': 55.631343841552734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 13.346324920654297; Loss Difference: 0.0, Decision: 0
Round 46 took 2.5559048652648926s, results:
{'t': 45, 'current_accuracy': 0.16796875, 'current_loss': 56.17437744140625, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 13.644681930541992; Loss Difference: 0.0, Decision: 0
Round 47 took 2.6116604804992676s, results:
{'t': 46, 'current_accuracy': 0.16796875, 'current_loss': 56.472734451293945, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 14.671026229858398; Loss Difference: 0.0, Decision: 0
Round 48 took 2.5593719482421875s, results:
{'t': 47, 'current_accuracy': 0.1640625, 'current_loss': 57.49907875061035, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 14.532964706420898; Loss Difference: 0.0, Decision: 0
Round 49 took 2.6485137939453125s, results:
{'t': 48, 'current_accuracy': 0.16796875, 'current_loss': 57.36101722717285, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 15.144536972045898; Loss Difference: 0.0, Decision: 0
Round 50 took 2.675757884979248s, results:
{'t': 49, 'current_accuracy': 0.1640625, 'current_loss': 57.97258949279785, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 14.729909896850586; Loss Difference: 0.0, Decision: 0
Round 51 took 2.499718189239502s, results:
{'t': 50, 'current_accuracy': 0.1640625, 'current_loss': 57.55796241760254, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['photo']}
Loss historical diff: 15.115058898925781; Loss Difference: 0.0, Decision: 0
Round 52 took 2.5488221645355225s, results:
{'t': 51, 'current_accuracy': 0.16015625, 'current_loss': 57.943111419677734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['photo']}
Loss historical diff: 15.26919174194336; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

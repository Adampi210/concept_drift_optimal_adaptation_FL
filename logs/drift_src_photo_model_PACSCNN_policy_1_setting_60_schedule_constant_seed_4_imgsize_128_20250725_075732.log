Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 28.05190086364746
<__main__.Policy object at 0x150911249a60>
28.05190086364746
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 1 took 2.9588491916656494s, results:
{'t': 0, 'current_accuracy': 0.13671875, 'current_loss': 28.03896713256836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.06552886962890625; Loss Difference: 0.0, Decision: 0
Round 2 took 2.653712034225464s, results:
{'t': 1, 'current_accuracy': 0.13671875, 'current_loss': 28.104496002197266, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.155609130859375; Loss Difference: 0.0, Decision: 0
Round 3 took 2.8941650390625s, results:
{'t': 2, 'current_accuracy': 0.13671875, 'current_loss': 28.194576263427734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 4 took 2.8394322395324707s, results:
{'t': 3, 'current_accuracy': 0.13671875, 'current_loss': 27.998116493225098, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 5 took 3.096649646759033s, results:
{'t': 4, 'current_accuracy': 0.13671875, 'current_loss': 27.792020797729492, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.05154705047607422; Loss Difference: 0.0, Decision: 0
Round 6 took 3.4895286560058594s, results:
{'t': 5, 'current_accuracy': 0.140625, 'current_loss': 27.843567848205566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 7 took 2.893852710723877s, results:
{'t': 6, 'current_accuracy': 0.140625, 'current_loss': 27.785969734191895, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 8 took 2.7478811740875244s, results:
{'t': 7, 'current_accuracy': 0.1484375, 'current_loss': 27.583609580993652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.15169334411621094; Loss Difference: 0.0, Decision: 0
Round 9 took 2.7917227745056152s, results:
{'t': 8, 'current_accuracy': 0.1484375, 'current_loss': 27.735302925109863, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.054848670959472656; Loss Difference: 0.0, Decision: 0
Round 10 took 2.7680470943450928s, results:
{'t': 9, 'current_accuracy': 0.15625, 'current_loss': 27.638458251953125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.2133035659790039; Loss Difference: 0.0, Decision: 0
Round 11 took 2.9180781841278076s, results:
{'t': 10, 'current_accuracy': 0.15625, 'current_loss': 27.796913146972656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 12 took 2.734187126159668s, results:
{'t': 11, 'current_accuracy': 0.16015625, 'current_loss': 27.342724800109863, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.20277786254882812; Loss Difference: 0.0, Decision: 0
Round 13 took 2.644895315170288s, results:
{'t': 12, 'current_accuracy': 0.16015625, 'current_loss': 27.54550266265869, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 1
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 77, in update_steps
    loss.backward()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
Exception in thread Thread-31 (_pin_memory_loop):
Traceback (most recent call last):
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 54, in _pin_memory_loop
    do_one_step()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 31, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
         ^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/resource_sharer.py", line 57, in detach

Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 25.70623016357422
<__main__.Policy object at 0x14b88e98d3a0>
25.70623016357422
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 1 took 3.5022060871124268s, results:
{'t': 0, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 2 took 3.445849657058716s, results:
{'t': 1, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 3 took 3.896134614944458s, results:
{'t': 2, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 4 took 3.426816701889038s, results:
{'t': 3, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 5 took 3.5543875694274902s, results:
{'t': 4, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 6 took 3.8694231510162354s, results:
{'t': 5, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 7 took 3.9911813735961914s, results:
{'t': 6, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 8 took 3.980823278427124s, results:
{'t': 7, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 9 took 3.8357064723968506s, results:
{'t': 8, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 10 took 3.812603235244751s, results:
{'t': 9, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 11 took 4.061597585678101s, results:
{'t': 10, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 12 took 3.9108619689941406s, results:
{'t': 11, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 13 took 3.8656630516052246s, results:
{'t': 12, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 14 took 3.425507068634033s, results:
{'t': 13, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 15 took 3.747835159301758s, results:
{'t': 14, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723759651184082; Loss Difference: 0.0, Decision: 0
Round 16 took 3.9107353687286377s, results:
{'t': 15, 'current_accuracy': 0.15625, 'current_loss': 28.4299898147583, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 17 took 4.024336814880371s, results:
{'t': 16, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 18 took 3.133248805999756s, results:
{'t': 17, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 19 took 3.5556795597076416s, results:
{'t': 18, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 20 took 3.809274196624756s, results:
{'t': 19, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 21 took 3.6367647647857666s, results:
{'t': 20, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 22 took 3.720317840576172s, results:
{'t': 21, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 23 took 4.185975074768066s, results:
{'t': 22, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 24 took 3.673205614089966s, results:
{'t': 23, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 25 took 3.8945627212524414s, results:
{'t': 24, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 26 took 4.052139043807983s, results:
{'t': 25, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 27 took 3.463541030883789s, results:
{'t': 26, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 28 took 3.7799510955810547s, results:
{'t': 27, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237586975097656; Loss Difference: 0.0, Decision: 0
Round 29 took 3.5864598751068115s, results:
{'t': 28, 'current_accuracy': 0.15625, 'current_loss': 28.429988861083984, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 30 took 3.6041207313537598s, results:
{'t': 29, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 31 took 4.163712501525879s, results:
{'t': 30, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 32 took 3.799600839614868s, results:
{'t': 31, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 33 took 3.662926435470581s, results:
{'t': 32, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 34 took 3.605459451675415s, results:
{'t': 33, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 35 took 3.9347848892211914s, results:
{'t': 34, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 36 took 3.688506603240967s, results:
{'t': 35, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 37 took 3.890371322631836s, results:
{'t': 36, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 38 took 3.637615203857422s, results:
{'t': 37, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 39 took 3.2702724933624268s, results:
{'t': 38, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237634658813477; Loss Difference: 0.0, Decision: 0
Round 40 took 3.5009567737579346s, results:
{'t': 39, 'current_accuracy': 0.15625, 'current_loss': 28.429993629455566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 41 took 3.601945161819458s, results:
{'t': 40, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 42 took 4.145436763763428s, results:
{'t': 41, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 43 took 3.7404069900512695s, results:
{'t': 42, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 44 took 3.4361305236816406s, results:
{'t': 43, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 45 took 3.4330806732177734s, results:
{'t': 44, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 46 took 3.188408136367798s, results:
{'t': 45, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 47 took 3.755286931991577s, results:
{'t': 46, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 48 took 3.859022855758667s, results:
{'t': 47, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 49 took 3.3780856132507324s, results:
{'t': 48, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 50 took 3.4995434284210205s, results:
{'t': 49, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 51 took 3.6481709480285645s, results:
{'t': 50, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 52 took 3.53889799118042s, results:
{'t': 51, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 53 took 3.238957166671753s, results:
{'t': 52, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 54 took 3.5203335285186768s, results:
{'t': 53, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723764419555664; Loss Difference: 0.0, Decision: 0
Round 55 took 3.6957781314849854s, results:
{'t': 54, 'current_accuracy': 0.15625, 'current_loss': 28.429994583129883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237653732299805; Loss Difference: 0.0, Decision: 0
Round 56 took 3.757279634475708s, results:
{'t': 55, 'current_accuracy': 0.15625, 'current_loss': 28.4299955368042, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.723761558532715; Loss Difference: 0.0, Decision: 0
Round 57 took 3.370880603790283s, results:
{'t': 56, 'current_accuracy': 0.15625, 'current_loss': 28.429991722106934, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 58 took 3.557478666305542s, results:
{'t': 57, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237625122070312; Loss Difference: 0.0, Decision: 0
Round 59 took 3.4374163150787354s, results:
{'t': 58, 'current_accuracy': 0.15625, 'current_loss': 28.42999267578125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.7237606048583984; Loss Difference: 0.0, Decision: 0
Round 60 took 3.061344861984253s, results:
{'t': 59, 'current_accuracy': 0.15625, 'current_loss': 28.429990768432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['art_painting']}
Loss historical diff: 2.6669740676879883; Loss Difference: 0.0, Decision: 0
Round 61 took 3.3288919925689697s, results:
{'t': 60, 'current_accuracy': 0.16015625, 'current_loss': 28.373204231262207, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7910690307617188; Loss Difference: 0.0, Decision: 0
Round 62 took 3.605640411376953s, results:
{'t': 61, 'current_accuracy': 0.16015625, 'current_loss': 28.497299194335938, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9957046508789062; Loss Difference: 0.0, Decision: 0
Round 63 took 3.284349203109741s, results:
{'t': 62, 'current_accuracy': 0.16015625, 'current_loss': 28.701934814453125, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.8634824752807617; Loss Difference: 0.0, Decision: 0
Round 64 took 3.7602767944335938s, results:
{'t': 63, 'current_accuracy': 0.16015625, 'current_loss': 28.56971263885498, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.719700813293457; Loss Difference: 0.0, Decision: 0
Round 65 took 3.1521761417388916s, results:
{'t': 64, 'current_accuracy': 0.16015625, 'current_loss': 28.425930976867676, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.835566520690918; Loss Difference: 0.0, Decision: 0
Round 66 took 3.8850584030151367s, results:
{'t': 65, 'current_accuracy': 0.16015625, 'current_loss': 28.541796684265137, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.819857597351074; Loss Difference: 0.0, Decision: 0
Round 67 took 3.943533420562744s, results:
{'t': 66, 'current_accuracy': 0.16015625, 'current_loss': 28.526087760925293, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9458351135253906; Loss Difference: 0.0, Decision: 0
Round 68 took 3.550649642944336s, results:
{'t': 67, 'current_accuracy': 0.15625, 'current_loss': 28.65206527709961, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.941516876220703; Loss Difference: 0.0, Decision: 0
Round 69 took 3.7385804653167725s, results:
{'t': 68, 'current_accuracy': 0.15625, 'current_loss': 28.647747039794922, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9712677001953125; Loss Difference: 0.0, Decision: 0
Round 70 took 3.81911563873291s, results:
{'t': 69, 'current_accuracy': 0.15234375, 'current_loss': 28.67749786376953, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.872197151184082; Loss Difference: 0.0, Decision: 0
Round 71 took 3.2222373485565186s, results:
{'t': 70, 'current_accuracy': 0.15234375, 'current_loss': 28.5784273147583, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7983665466308594; Loss Difference: 0.0, Decision: 0
Round 72 took 3.5775015354156494s, results:
{'t': 71, 'current_accuracy': 0.15234375, 'current_loss': 28.504596710205078, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9882678985595703; Loss Difference: 0.0, Decision: 0
Round 73 took 3.779775381088257s, results:
{'t': 72, 'current_accuracy': 0.15234375, 'current_loss': 28.69449806213379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7083568572998047; Loss Difference: 0.0, Decision: 0
Round 74 took 3.4651834964752197s, results:
{'t': 73, 'current_accuracy': 0.15625, 'current_loss': 28.414587020874023, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.70589542388916; Loss Difference: 0.0, Decision: 0
Round 75 took 3.6613264083862305s, results:
{'t': 74, 'current_accuracy': 0.15625, 'current_loss': 28.41212558746338, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.775984764099121; Loss Difference: 0.0, Decision: 0
Round 76 took 3.4791383743286133s, results:
{'t': 75, 'current_accuracy': 0.15625, 'current_loss': 28.48221492767334, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.1095142364501953; Loss Difference: 0.0, Decision: 0
Round 77 took 3.8792343139648438s, results:
{'t': 76, 'current_accuracy': 0.15234375, 'current_loss': 28.815744400024414, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.263911247253418; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

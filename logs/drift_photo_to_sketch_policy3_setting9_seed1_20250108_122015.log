/home/apiasecz/.conda/envs/cent7/2024.02-py311/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return F.conv2d(input, weight, bias, self.stride,
seed: 1
policy_id: 3
setting_id: 9
pi_bar: 0.3
drift_rate: 0.01
V: 5
0.01727128841660236 0.04
Round 0: Accuracy = 0.7979, Decision = 0
0.014791047031229188 0.04
Round 1: Accuracy = 0.7863, Decision = 0
0.018421166322448057 0.04
Round 2: Accuracy = 0.7788, Decision = 0
0.012005182603995024 0.04
Round 3: Accuracy = 0.7741, Decision = 0
0.008845273405313492 0.04
Round 4: Accuracy = 0.7671, Decision = 0
0.0326710008084774 0.04
Round 5: Accuracy = 0.7553, Decision = 0
0.02423912286758423 0.04
Round 6: Accuracy = 0.7538, Decision = 0
0.023173941920200947 0.04
Round 7: Accuracy = 0.7454, Decision = 0
0.00913003459572792 0.04
Round 8: Accuracy = 0.7418, Decision = 0
0.018962492545445797 0.04
Round 9: Accuracy = 0.7384, Decision = 0
0.024470455944538116 0.04
Round 10: Accuracy = 0.7294, Decision = 0
0.00821857899427414 0.04
Round 11: Accuracy = 0.7237, Decision = 0
0.008420715347314423 0.04
Round 12: Accuracy = 0.7207, Decision = 0
0.04534213818036603 0.04
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 309, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 292, in main
    results = retrain_with_policy_under_drift(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 192, in retrain_with_policy_under_drift
    decision = policy.policy_decision(decision_id=policy_id, pi_bar=pi_bar, V=V, current_time=t, loss_diff=loss_array[-1] - loss_array[-2]) 
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/test_loss_behavior_under_drift.py", line 91, in policy_decision
    self.update_history.append(current_time)
                               ^^^^^^^^^^^^
NameError: name 'current_time' is not defined. Did you mean: 'current_tme'?

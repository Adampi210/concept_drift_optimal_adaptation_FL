Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 32.75410842895508
<__main__.Policy object at 0x1475012956d0>
32.75410842895508
Loss historical diff: 2.910219192504883; Loss Difference: 0.0, Decision: 0
Round 1 took 2.8346946239471436s, results:
{'t': 0, 'current_accuracy': 0.1015625, 'current_loss': 35.66432762145996, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.0636520385742188; Loss Difference: 0.0, Decision: 0
Round 2 took 5.738663673400879s, results:
{'t': 1, 'current_accuracy': 0.09765625, 'current_loss': 35.8177604675293, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.385133743286133; Loss Difference: 0.0, Decision: 0
Round 3 took 4.344748020172119s, results:
{'t': 2, 'current_accuracy': 0.09765625, 'current_loss': 36.13924217224121, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.7831592559814453; Loss Difference: 0.0, Decision: 0
Round 4 took 4.66079306602478s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 36.53726768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.6786632537841797; Loss Difference: 0.0, Decision: 0
Round 5 took 4.296648025512695s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 36.43277168273926, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.533853530883789; Loss Difference: 0.0, Decision: 0
Round 6 took 4.170486688613892s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 36.28796195983887, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.654449462890625; Loss Difference: 0.0, Decision: 0
Round 7 took 3.9357519149780273s, results:
{'t': 6, 'current_accuracy': 0.09765625, 'current_loss': 36.4085578918457, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.865802764892578; Loss Difference: 0.0, Decision: 0
Round 8 took 4.461666107177734s, results:
{'t': 7, 'current_accuracy': 0.1015625, 'current_loss': 36.619911193847656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.9278297424316406; Loss Difference: 0.0, Decision: 0
Round 9 took 4.131396532058716s, results:
{'t': 8, 'current_accuracy': 0.1015625, 'current_loss': 36.68193817138672, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.578277587890625; Loss Difference: 0.0, Decision: 0
Round 10 took 4.741988182067871s, results:
{'t': 9, 'current_accuracy': 0.1015625, 'current_loss': 36.3323860168457, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.1974029541015625; Loss Difference: 0.0, Decision: 0
Round 11 took 4.8890204429626465s, results:
{'t': 10, 'current_accuracy': 0.10546875, 'current_loss': 35.95151138305664, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.1371612548828125; Loss Difference: 0.0, Decision: 0
Round 12 took 4.437627553939819s, results:
{'t': 11, 'current_accuracy': 0.10546875, 'current_loss': 35.89126968383789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.3140697479248047; Loss Difference: 0.0, Decision: 0
Round 13 took 4.1209447383880615s, results:
{'t': 12, 'current_accuracy': 0.10546875, 'current_loss': 36.06817817687988, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.286703109741211; Loss Difference: 0.0, Decision: 0
Round 14 took 4.529121398925781s, results:
{'t': 13, 'current_accuracy': 0.109375, 'current_loss': 36.04081153869629, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.663301467895508; Loss Difference: 0.0, Decision: 0
Round 15 took 4.3938727378845215s, results:
{'t': 14, 'current_accuracy': 0.12109375, 'current_loss': 35.417409896850586, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.2886829376220703; Loss Difference: 0.0, Decision: 0
Round 16 took 4.110870122909546s, results:
{'t': 15, 'current_accuracy': 0.12890625, 'current_loss': 35.04279136657715, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.9886131286621094; Loss Difference: 0.0, Decision: 0
Round 17 took 3.720794677734375s, results:
{'t': 16, 'current_accuracy': 0.1328125, 'current_loss': 34.74272155761719, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.196277618408203; Loss Difference: 0.0, Decision: 0
Round 18 took 3.9115028381347656s, results:
{'t': 17, 'current_accuracy': 0.1328125, 'current_loss': 34.95038604736328, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.269868850708008; Loss Difference: 0.0, Decision: 0
Round 19 took 4.148291110992432s, results:
{'t': 18, 'current_accuracy': 0.1328125, 'current_loss': 35.023977279663086, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.138864517211914; Loss Difference: 0.0, Decision: 0
Round 20 took 3.9627397060394287s, results:
{'t': 19, 'current_accuracy': 0.1328125, 'current_loss': 34.89297294616699, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.4428329467773438; Loss Difference: 0.0, Decision: 0
Round 21 took 3.6130692958831787s, results:
{'t': 20, 'current_accuracy': 0.12890625, 'current_loss': 35.19694137573242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.4862613677978516; Loss Difference: 0.0, Decision: 0
Round 22 took 3.691594362258911s, results:
{'t': 21, 'current_accuracy': 0.125, 'current_loss': 35.24036979675293, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.4616470336914062; Loss Difference: 0.0, Decision: 0
Round 23 took 3.847621440887451s, results:
{'t': 22, 'current_accuracy': 0.125, 'current_loss': 35.215755462646484, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.7124786376953125; Loss Difference: 0.0, Decision: 0
Round 24 took 4.046318292617798s, results:
{'t': 23, 'current_accuracy': 0.12109375, 'current_loss': 35.46658706665039, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.704700469970703; Loss Difference: 0.0, Decision: 0
Round 25 took 3.9365878105163574s, results:
{'t': 24, 'current_accuracy': 0.12109375, 'current_loss': 35.45880889892578, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.2485713958740234; Loss Difference: 0.0, Decision: 0
Round 26 took 4.296968698501587s, results:
{'t': 25, 'current_accuracy': 0.1328125, 'current_loss': 35.0026798248291, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.283191680908203; Loss Difference: 0.0, Decision: 0
Round 27 took 3.9313368797302246s, results:
{'t': 26, 'current_accuracy': 0.1328125, 'current_loss': 35.03730010986328, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.1108341217041016; Loss Difference: 0.0, Decision: 0
Round 28 took 3.7347981929779053s, results:
{'t': 27, 'current_accuracy': 0.1328125, 'current_loss': 34.86494255065918, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.055753707885742; Loss Difference: 0.0, Decision: 0
Round 29 took 3.9089338779449463s, results:
{'t': 28, 'current_accuracy': 0.1328125, 'current_loss': 34.80986213684082, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.7932567596435547; Loss Difference: 0.0, Decision: 0
Round 30 took 3.54914927482605s, results:
{'t': 29, 'current_accuracy': 0.1328125, 'current_loss': 34.54736518859863, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.5933189392089844; Loss Difference: 0.0, Decision: 0
Round 31 took 3.7454776763916016s, results:
{'t': 30, 'current_accuracy': 0.1328125, 'current_loss': 34.34742736816406, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.991067886352539; Loss Difference: 0.0, Decision: 0
Round 32 took 3.7357394695281982s, results:
{'t': 31, 'current_accuracy': 0.12890625, 'current_loss': 34.74517631530762, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.0014209747314453; Loss Difference: 0.0, Decision: 0
Round 33 took 3.694593667984009s, results:
{'t': 32, 'current_accuracy': 0.12890625, 'current_loss': 34.75552940368652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.6611366271972656; Loss Difference: 0.0, Decision: 0
Round 34 took 4.340332269668579s, results:
{'t': 33, 'current_accuracy': 0.12890625, 'current_loss': 34.415245056152344, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4975051879882812; Loss Difference: 0.0, Decision: 0
Round 35 took 3.809981346130371s, results:
{'t': 34, 'current_accuracy': 0.12890625, 'current_loss': 34.25161361694336, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.2764892578125; Loss Difference: 0.0, Decision: 0
Round 36 took 3.912200689315796s, results:
{'t': 35, 'current_accuracy': 0.12890625, 'current_loss': 34.03059768676758, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.0805435180664062; Loss Difference: 0.0, Decision: 0
Round 37 took 3.7106051445007324s, results:
{'t': 36, 'current_accuracy': 0.125, 'current_loss': 33.834651947021484, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.8330841064453125; Loss Difference: 0.0, Decision: 0
Round 38 took 3.848780870437622s, results:
{'t': 37, 'current_accuracy': 0.125, 'current_loss': 33.58719253540039, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.5837783813476562; Loss Difference: 0.0, Decision: 0
Round 39 took 4.147779226303101s, results:
{'t': 38, 'current_accuracy': 0.12890625, 'current_loss': 33.337886810302734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.7228927612304688; Loss Difference: 0.0, Decision: 0
Round 40 took 3.896260976791382s, results:
{'t': 39, 'current_accuracy': 0.12890625, 'current_loss': 33.47700119018555, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.5253868103027344; Loss Difference: 0.0, Decision: 0
Round 41 took 3.961052656173706s, results:
{'t': 40, 'current_accuracy': 0.12890625, 'current_loss': 33.27949523925781, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.4044208526611328; Loss Difference: 0.0, Decision: 0
Round 42 took 4.156131029129028s, results:
{'t': 41, 'current_accuracy': 0.12890625, 'current_loss': 33.15852928161621, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.39121055603027344; Loss Difference: 0.0, Decision: 0
Round 43 took 3.5938055515289307s, results:
{'t': 42, 'current_accuracy': 0.12890625, 'current_loss': 33.14531898498535, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.12582778930664062; Loss Difference: 0.0, Decision: 0
Round 44 took 3.931765079498291s, results:
{'t': 43, 'current_accuracy': 0.1328125, 'current_loss': 32.87993621826172, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.19466400146484375; Loss Difference: 0.0, Decision: 0
Round 45 took 4.14810037612915s, results:
{'t': 44, 'current_accuracy': 0.13671875, 'current_loss': 32.94877243041992, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 46 took 4.027168273925781s, results:
{'t': 45, 'current_accuracy': 0.140625, 'current_loss': 32.54307746887207, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.028348922729492188; Loss Difference: 0.0, Decision: 0
Round 47 took 3.911262273788452s, results:
{'t': 46, 'current_accuracy': 0.140625, 'current_loss': 32.57142639160156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 48 took 4.099916696548462s, results:
{'t': 47, 'current_accuracy': 0.140625, 'current_loss': 32.359174728393555, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.15645599365234375; Loss Difference: 0.0, Decision: 0
Round 49 took 4.091967821121216s, results:
{'t': 48, 'current_accuracy': 0.14453125, 'current_loss': 32.5156307220459, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.48996734619140625; Loss Difference: 0.0, Decision: 0
Round 50 took 4.058792591094971s, results:
{'t': 49, 'current_accuracy': 0.140625, 'current_loss': 32.84914207458496, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.7912025451660156; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

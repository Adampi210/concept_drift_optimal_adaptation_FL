Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 29.05497169494629
<__main__.Policy object at 0x145ddf97d6d0>
29.05497169494629
Loss historical diff: 0.0; Loss Difference: 0.0, Decision: 0
Round 1 took 3.7024714946746826s, results:
{'t': 0, 'current_accuracy': 0.1953125, 'current_loss': 25.868717193603516, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.24242019653320312; Loss Difference: 0.0, Decision: 0
Round 2 took 3.662708044052124s, results:
{'t': 1, 'current_accuracy': 0.1953125, 'current_loss': 26.11113739013672, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.47005558013916016; Loss Difference: 0.0, Decision: 0
Round 3 took 3.8287692070007324s, results:
{'t': 2, 'current_accuracy': 0.19140625, 'current_loss': 26.338772773742676, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 0.8186845779418945; Loss Difference: 0.0, Decision: 0
Round 4 took 3.6780121326446533s, results:
{'t': 3, 'current_accuracy': 0.1875, 'current_loss': 26.68740177154541, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.0958728790283203; Loss Difference: 0.0, Decision: 0
Round 5 took 3.382957696914673s, results:
{'t': 4, 'current_accuracy': 0.18359375, 'current_loss': 26.964590072631836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.4442462921142578; Loss Difference: 0.0, Decision: 0
Round 6 took 3.585404872894287s, results:
{'t': 5, 'current_accuracy': 0.171875, 'current_loss': 27.312963485717773, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.395829200744629; Loss Difference: 0.0, Decision: 0
Round 7 took 3.6708567142486572s, results:
{'t': 6, 'current_accuracy': 0.171875, 'current_loss': 27.264546394348145, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.557063102722168; Loss Difference: 0.0, Decision: 0
Round 8 took 3.652177572250366s, results:
{'t': 7, 'current_accuracy': 0.16796875, 'current_loss': 27.425780296325684, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 1.934525489807129; Loss Difference: 0.0, Decision: 0
Round 9 took 3.896007537841797s, results:
{'t': 8, 'current_accuracy': 0.1640625, 'current_loss': 27.803242683410645, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.1498842239379883; Loss Difference: 0.0, Decision: 0
Round 10 took 3.7877724170684814s, results:
{'t': 9, 'current_accuracy': 0.1640625, 'current_loss': 28.018601417541504, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.8011035919189453; Loss Difference: 0.0, Decision: 0
Round 11 took 4.07077693939209s, results:
{'t': 10, 'current_accuracy': 0.16015625, 'current_loss': 28.66982078552246, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.743014335632324; Loss Difference: 0.0, Decision: 0
Round 12 took 3.742971897125244s, results:
{'t': 11, 'current_accuracy': 0.1640625, 'current_loss': 28.61173152923584, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.843502998352051; Loss Difference: 0.0, Decision: 0
Round 13 took 3.8290839195251465s, results:
{'t': 12, 'current_accuracy': 0.1640625, 'current_loss': 28.712220191955566, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.724811553955078; Loss Difference: 0.0, Decision: 0
Round 14 took 3.755819082260132s, results:
{'t': 13, 'current_accuracy': 0.1640625, 'current_loss': 28.593528747558594, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.889352798461914; Loss Difference: 0.0, Decision: 0
Round 15 took 3.843496799468994s, results:
{'t': 14, 'current_accuracy': 0.16015625, 'current_loss': 28.75806999206543, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 2.8618507385253906; Loss Difference: 0.0, Decision: 0
Round 16 took 4.1268532276153564s, results:
{'t': 15, 'current_accuracy': 0.16015625, 'current_loss': 28.730567932128906, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.365302085876465; Loss Difference: 0.0, Decision: 0
Round 17 took 4.389293432235718s, results:
{'t': 16, 'current_accuracy': 0.15234375, 'current_loss': 29.23401927947998, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.2484865188598633; Loss Difference: 0.0, Decision: 0
Round 18 took 3.617476224899292s, results:
{'t': 17, 'current_accuracy': 0.15234375, 'current_loss': 29.11720371246338, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.457404136657715; Loss Difference: 0.0, Decision: 0
Round 19 took 3.9182960987091064s, results:
{'t': 18, 'current_accuracy': 0.1484375, 'current_loss': 29.32612133026123, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.4947986602783203; Loss Difference: 0.0, Decision: 0
Round 20 took 3.951315402984619s, results:
{'t': 19, 'current_accuracy': 0.15625, 'current_loss': 29.363515853881836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.344353675842285; Loss Difference: 0.0, Decision: 0
Round 21 took 3.7067928314208984s, results:
{'t': 20, 'current_accuracy': 0.15625, 'current_loss': 29.2130708694458, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.4307947158813477; Loss Difference: 0.0, Decision: 0
Round 22 took 3.537713050842285s, results:
{'t': 21, 'current_accuracy': 0.1640625, 'current_loss': 29.299511909484863, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.180914878845215; Loss Difference: 0.0, Decision: 0
Round 23 took 3.6899452209472656s, results:
{'t': 22, 'current_accuracy': 0.16796875, 'current_loss': 29.04963207244873, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.345836639404297; Loss Difference: 0.0, Decision: 0
Round 24 took 3.8911168575286865s, results:
{'t': 23, 'current_accuracy': 0.16796875, 'current_loss': 29.214553833007812, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.5997982025146484; Loss Difference: 0.0, Decision: 0
Round 25 took 4.157646179199219s, results:
{'t': 24, 'current_accuracy': 0.16015625, 'current_loss': 29.468515396118164, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.2120895385742188; Loss Difference: 0.0, Decision: 0
Round 26 took 3.691629648208618s, results:
{'t': 25, 'current_accuracy': 0.1640625, 'current_loss': 29.080806732177734, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.271953582763672; Loss Difference: 0.0, Decision: 0
Round 27 took 3.6491384506225586s, results:
{'t': 26, 'current_accuracy': 0.1640625, 'current_loss': 29.140670776367188, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.063028335571289; Loss Difference: 0.0, Decision: 0
Round 28 took 3.570079803466797s, results:
{'t': 27, 'current_accuracy': 0.16796875, 'current_loss': 28.931745529174805, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.5662460327148438; Loss Difference: 0.0, Decision: 0
Round 29 took 3.7415378093719482s, results:
{'t': 28, 'current_accuracy': 0.16796875, 'current_loss': 29.43496322631836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.8714780807495117; Loss Difference: 0.0, Decision: 0
Round 30 took 3.4375298023223877s, results:
{'t': 29, 'current_accuracy': 0.1640625, 'current_loss': 29.740195274353027, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.515378952026367; Loss Difference: 0.0, Decision: 0
Round 31 took 3.916053533554077s, results:
{'t': 30, 'current_accuracy': 0.171875, 'current_loss': 29.384096145629883, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.9268741607666016; Loss Difference: 0.0, Decision: 0
Round 32 took 4.011056661605835s, results:
{'t': 31, 'current_accuracy': 0.16796875, 'current_loss': 29.795591354370117, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.277277946472168; Loss Difference: 0.0, Decision: 0
Round 33 took 3.872972011566162s, results:
{'t': 32, 'current_accuracy': 0.1640625, 'current_loss': 30.145995140075684, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 3.9678993225097656; Loss Difference: 0.0, Decision: 0
Round 34 took 3.7745792865753174s, results:
{'t': 33, 'current_accuracy': 0.1640625, 'current_loss': 29.83661651611328, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.256173133850098; Loss Difference: 0.0, Decision: 0
Round 35 took 3.7922439575195312s, results:
{'t': 34, 'current_accuracy': 0.16015625, 'current_loss': 30.124890327453613, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.314726829528809; Loss Difference: 0.0, Decision: 0
Round 36 took 4.076721668243408s, results:
{'t': 35, 'current_accuracy': 0.16015625, 'current_loss': 30.183444023132324, 'train_loss': None, 'decision': 0, 'drift_rate': 0.016, 'target_domains': ['sketch']}
Loss historical diff: 4.620360374450684; Loss Difference: 0.0, Decision: 1
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 77, in update_steps
    loss.backward()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
Exception in thread Thread-77 (_pin_memory_loop):
Traceback (most recent call last):
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1073, in _bootstrap_inner
    self.run()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/threading.py", line 1010, in run
    self._target(*self._args, **self._kwargs)
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 54, in _pin_memory_loop
    do_one_step()
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py", line 31, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/multiprocessing/reductions.py", line 495, in rebuild_storage_fd
    fd = df.detach()
         ^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 526, in Client
    deliver_challenge(c, authkey)
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 939, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 430, in _recv_bytes
    buf = self._recv(4)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/multiprocessing/connection.py", line 395, in _recv
    chunk = read(handle, remaining)
            ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

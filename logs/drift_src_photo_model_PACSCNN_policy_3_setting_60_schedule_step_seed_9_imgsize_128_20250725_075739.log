Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Using the latest cached version of the dataset since flwrlabs/pacs couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at /home/apiasecz/.cache/huggingface/datasets/flwrlabs___pacs/default/0.0.0/394113073258ead631f617d2e13bb377c0715c4b (last modified on Wed Jan 29 16:59:35 2025).
Device: cuda
CUDA Version: 12.1
cuDNN Version: 8902
PyTorch Version: 2.3.0

Model used: PACSCNN
Initial dataset creation
Initial dataset creation
Initial loss: 32.75410842895508
<__main__.Policy object at 0x14fe15c31b20>
32.75410842895508
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 1 took 2.944002389907837s, results:
{'t': 0, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 2 took 4.0220046043396s, results:
{'t': 1, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 3 took 4.015580177307129s, results:
{'t': 2, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 4 took 4.036015748977661s, results:
{'t': 3, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 5 took 3.9528417587280273s, results:
{'t': 4, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 6 took 3.558472156524658s, results:
{'t': 5, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 7 took 3.580120086669922s, results:
{'t': 6, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 8 took 3.8026301860809326s, results:
{'t': 7, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 9 took 3.612468719482422s, results:
{'t': 8, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 10 took 4.122194766998291s, results:
{'t': 9, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 11 took 3.9642090797424316s, results:
{'t': 10, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 12 took 4.379250526428223s, results:
{'t': 11, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 13 took 3.8166842460632324s, results:
{'t': 12, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 14 took 3.663407564163208s, results:
{'t': 13, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 15 took 3.909538507461548s, results:
{'t': 14, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 16 took 4.033820629119873s, results:
{'t': 15, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 17 took 3.845231056213379s, results:
{'t': 16, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 18 took 4.05440354347229s, results:
{'t': 17, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 19 took 3.8009445667266846s, results:
{'t': 18, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 20 took 4.119580507278442s, results:
{'t': 19, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 21 took 4.136063814163208s, results:
{'t': 20, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 22 took 3.6229519844055176s, results:
{'t': 21, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 23 took 4.498788833618164s, results:
{'t': 22, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 24 took 3.7780263423919678s, results:
{'t': 23, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 25 took 4.5091917514801025s, results:
{'t': 24, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 26 took 3.7711777687072754s, results:
{'t': 25, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 27 took 4.3246729373931885s, results:
{'t': 26, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 28 took 4.258671998977661s, results:
{'t': 27, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 29 took 3.9966721534729004s, results:
{'t': 28, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 30 took 4.294568061828613s, results:
{'t': 29, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 31 took 3.7385637760162354s, results:
{'t': 30, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 32 took 4.022052049636841s, results:
{'t': 31, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 33 took 3.852721691131592s, results:
{'t': 32, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 34 took 4.113311290740967s, results:
{'t': 33, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 35 took 4.3683021068573s, results:
{'t': 34, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 36 took 3.930727005004883s, results:
{'t': 35, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 37 took 4.005831003189087s, results:
{'t': 36, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 38 took 3.9704952239990234s, results:
{'t': 37, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 39 took 4.236122131347656s, results:
{'t': 38, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 40 took 4.17475438117981s, results:
{'t': 39, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 41 took 4.351964950561523s, results:
{'t': 40, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 42 took 3.5574522018432617s, results:
{'t': 41, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 43 took 3.678332805633545s, results:
{'t': 42, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 44 took 3.9302358627319336s, results:
{'t': 43, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 45 took 4.204689264297485s, results:
{'t': 44, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 46 took 4.305571794509888s, results:
{'t': 45, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 47 took 4.058044910430908s, results:
{'t': 46, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269092559814453; Loss Difference: 0.0, Decision: 0
Round 48 took 3.8699874877929688s, results:
{'t': 47, 'current_accuracy': 0.09375, 'current_loss': 35.88101768493652, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 49 took 3.9461398124694824s, results:
{'t': 48, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 50 took 3.983779191970825s, results:
{'t': 49, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 51 took 4.13013482093811s, results:
{'t': 50, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 52 took 3.8242318630218506s, results:
{'t': 51, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 53 took 3.976284980773926s, results:
{'t': 52, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126913070678711; Loss Difference: 0.0, Decision: 0
Round 54 took 3.881127119064331s, results:
{'t': 53, 'current_accuracy': 0.09375, 'current_loss': 35.88102149963379, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.126911163330078; Loss Difference: 0.0, Decision: 0
Round 55 took 4.52581524848938s, results:
{'t': 54, 'current_accuracy': 0.09375, 'current_loss': 35.881019592285156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269073486328125; Loss Difference: 0.0, Decision: 0
Round 56 took 3.698726177215576s, results:
{'t': 55, 'current_accuracy': 0.09375, 'current_loss': 35.88101577758789, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 57 took 3.862957715988159s, results:
{'t': 56, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 58 took 3.952674627304077s, results:
{'t': 57, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 59 took 4.3853936195373535s, results:
{'t': 58, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.1269149780273438; Loss Difference: 0.0, Decision: 0
Round 60 took 4.204707384109497s, results:
{'t': 59, 'current_accuracy': 0.09375, 'current_loss': 35.88102340698242, 'train_loss': None, 'decision': 0, 'drift_rate': 0.0, 'target_domains': ['photo']}
Loss historical diff: 3.016416549682617; Loss Difference: 0.0, Decision: 0
Round 61 took 4.293183326721191s, results:
{'t': 60, 'current_accuracy': 0.09375, 'current_loss': 35.770524978637695, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.872272491455078; Loss Difference: 0.0, Decision: 0
Round 62 took 3.7029361724853516s, results:
{'t': 61, 'current_accuracy': 0.09375, 'current_loss': 35.626380920410156, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9453907012939453; Loss Difference: 0.0, Decision: 0
Round 63 took 4.183963298797607s, results:
{'t': 62, 'current_accuracy': 0.09375, 'current_loss': 35.69949913024902, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.0142860412597656; Loss Difference: 0.0, Decision: 0
Round 64 took 4.2585670948028564s, results:
{'t': 63, 'current_accuracy': 0.09375, 'current_loss': 35.768394470214844, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.005462646484375; Loss Difference: 0.0, Decision: 0
Round 65 took 4.45065450668335s, results:
{'t': 64, 'current_accuracy': 0.09375, 'current_loss': 35.75957107543945, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.0090980529785156; Loss Difference: 0.0, Decision: 0
Round 66 took 4.117294073104858s, results:
{'t': 65, 'current_accuracy': 0.09375, 'current_loss': 35.763206481933594, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 3.009054183959961; Loss Difference: 0.0, Decision: 0
Round 67 took 4.354463338851929s, results:
{'t': 66, 'current_accuracy': 0.09375, 'current_loss': 35.76316261291504, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7983055114746094; Loss Difference: 0.0, Decision: 0
Round 68 took 4.177533149719238s, results:
{'t': 67, 'current_accuracy': 0.09765625, 'current_loss': 35.55241394042969, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9481430053710938; Loss Difference: 0.0, Decision: 0
Round 69 took 4.23490047454834s, results:
{'t': 68, 'current_accuracy': 0.09765625, 'current_loss': 35.70225143432617, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.8505859375; Loss Difference: 0.0, Decision: 0
Round 70 took 4.544509649276733s, results:
{'t': 69, 'current_accuracy': 0.1015625, 'current_loss': 35.60469436645508, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.905088424682617; Loss Difference: 0.0, Decision: 0
Round 71 took 4.232068300247192s, results:
{'t': 70, 'current_accuracy': 0.1015625, 'current_loss': 35.659196853637695, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7502574920654297; Loss Difference: 0.0, Decision: 0
Round 72 took 4.655202388763428s, results:
{'t': 71, 'current_accuracy': 0.1015625, 'current_loss': 35.50436592102051, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7814064025878906; Loss Difference: 0.0, Decision: 0
Round 73 took 4.333533525466919s, results:
{'t': 72, 'current_accuracy': 0.1015625, 'current_loss': 35.53551483154297, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.8301219940185547; Loss Difference: 0.0, Decision: 0
Round 74 took 3.861860990524292s, results:
{'t': 73, 'current_accuracy': 0.1015625, 'current_loss': 35.58423042297363, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.723936080932617; Loss Difference: 0.0, Decision: 0
Round 75 took 4.523665189743042s, results:
{'t': 74, 'current_accuracy': 0.1015625, 'current_loss': 35.478044509887695, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.9360389709472656; Loss Difference: 0.0, Decision: 0
Round 76 took 3.936795711517334s, results:
{'t': 75, 'current_accuracy': 0.1015625, 'current_loss': 35.690147399902344, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.7990074157714844; Loss Difference: 0.0, Decision: 0
Round 77 took 3.927485466003418s, results:
{'t': 76, 'current_accuracy': 0.1015625, 'current_loss': 35.55311584472656, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.6750755310058594; Loss Difference: 0.0, Decision: 0
Round 78 took 4.137139797210693s, results:
{'t': 77, 'current_accuracy': 0.1015625, 'current_loss': 35.42918395996094, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.524934768676758; Loss Difference: 0.0, Decision: 0
Round 79 took 4.227786540985107s, results:
{'t': 78, 'current_accuracy': 0.1015625, 'current_loss': 35.279043197631836, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.4440040588378906; Loss Difference: 0.0, Decision: 0
Round 80 took 3.9997758865356445s, results:
{'t': 79, 'current_accuracy': 0.1015625, 'current_loss': 35.19811248779297, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.5007896423339844; Loss Difference: 0.0, Decision: 0
Round 81 took 4.2139222621917725s, results:
{'t': 80, 'current_accuracy': 0.1015625, 'current_loss': 35.25489807128906, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.4130306243896484; Loss Difference: 0.0, Decision: 0
Round 82 took 3.9815356731414795s, results:
{'t': 81, 'current_accuracy': 0.1015625, 'current_loss': 35.16713905334473, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.5569400787353516; Loss Difference: 0.0, Decision: 0
Round 83 took 4.347357749938965s, results:
{'t': 82, 'current_accuracy': 0.1015625, 'current_loss': 35.31104850769043, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.5611305236816406; Loss Difference: 0.0, Decision: 0
Round 84 took 4.2341148853302s, results:
{'t': 83, 'current_accuracy': 0.1015625, 'current_loss': 35.31523895263672, 'train_loss': None, 'decision': 0, 'drift_rate': 0.006, 'target_domains': ['cartoon']}
Loss historical diff: 2.8552112579345703; Loss Difference: 0.0, Decision: 1
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.00 GiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 514.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 258.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 516.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 770.00 MiB. GPU  (Triggered internally at /opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)
  return F.conv2d(input, weight, bias, self.stride,
Traceback (most recent call last):
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 753, in <module>
    main()
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 733, in main
    evaluate_policy_under_drift(
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 554, in evaluate_policy_under_drift
    update_loss = agent_train.update_steps(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/federated/client.py", line 202, in update_steps
    return self.model.update_steps(self.data_loader, optimizer, loss_fn, num_updates, verbose)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/Federated_Learning_Base_Toolkit_torch/fl_toolkit/models/base_model.py", line 75, in update_steps
    outputs = self.model(inputs)
              ^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 47, in forward
    x = self.features(x)
        ^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/programming/concept_drift_optimal_adaptation_FL/src/execute/evaluate_policy.py", line 70, in forward
    out = self.bn1(out)
          ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py", line 175, in forward
    return F.batch_norm(
           ^^^^^^^^^^^^^
  File "/home/apiasecz/.conda/envs/cog_fl_llm_env/lib/python3.12/site-packages/torch/nn/functional.py", line 2509, in batch_norm
    return torch.batch_norm(
           ^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 

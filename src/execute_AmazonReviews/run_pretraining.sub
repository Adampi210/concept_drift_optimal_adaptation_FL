#!/bin/bash
#SBATCH -A cgb                  # Account name (adjust as needed)
#SBATCH -p ai                   # Partition
#SBATCH -q preemptible          # Queue
#SBATCH --nodes=1               # Number of nodes
#SBATCH --ntasks=1              # Number of tasks per node
#SBATCH --cpus-per-task=14      # CPUs per task
#SBATCH --gpus-per-node=1       # GPUs per node
#SBATCH --time=12:00:00         # Time limit (adjust as needed)
#SBATCH --array=0-9             # Creates a job array with tasks ID from 0 to 9

# Define the name of your python script
PYTHON_SCRIPT="pretrain_models_MC4.py"

# Define the output directory for Slurm logs
# This will create separate log files for each job in the array
LOG_DIR="slurm_logs"
mkdir -p $LOG_DIR
#SBATCH -o ${LOG_DIR}/slurm-%A_%a.out  # Standard output, %A is Job ID, %a is array task ID
#SBATCH -e ${LOG_DIR}/slurm-%A_%a.err  # Standard error

# Load necessary modules (adjust based on your system)
echo "Loading modules..."
module load cuda
module load conda

# Activate the Conda environment (adjust environment name as needed)
echo "Activating Conda environment..."
source activate cog_fl_llm_env

# The SLURM_ARRAY_TASK_ID variable is automatically set by Slurm for each job in the array.
# It will be 0 for the first job, 1 for the second, and so on, up to 9.
echo "Starting job for seed: $SLURM_ARRAY_TASK_ID"

# Execute the script with the assigned seed from the job array
# Each job will run this command with a different value for $SLURM_ARRAY_TASK_ID
python3 ${PYTHON_SCRIPT} --seed ${SLURM_ARRAY_TASK_ID}

# Wait for the python script to finish before the job ends
wait

echo "Job for seed $SLURM_ARRAY_TASK_ID finished."
